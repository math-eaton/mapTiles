{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64af477f",
   "metadata": {},
   "source": [
    "# VECTOR TILING FOR MAP GENERALIZATION\n",
    "\n",
    "Generalization means creating many copies of a single â€˜source of truthâ€™ and tailoring them to the view context\n",
    "\n",
    "Doing this on the fly is labor intensive in a static paper mapping context, especially en masse with variable map scales and contexts (urban, semi-urban, rural) \n",
    "\n",
    "Value in adopting dynamic mapping techniques into the existing processing workflow:\n",
    "\n",
    "- Vector tiling: highly optimized, customizable, retains recordsâ€™ attributes (versus image tiles)\n",
    "- Customization, filtering, alignment between 'in-house' GRID3 data and third-party sources like OpenStreetMap\n",
    "- API endpoint targets: maps can diff and grow as the sources of truth do\n",
    "- TIPPECANOE: Incredible and fast processing library, somewhat unpredictable w/ emergent effects when processing geometries in a â€˜recursive tiledâ€™ manner, but benefits outweigh headaches\n",
    "- Plus: Self-hosting interest (docker/containerization): anxiety after â€˜openâ€™ data portals going offline nationwide\n",
    "\n",
    "\n",
    "\n",
    "<!-- - What works?\n",
    "\n",
    "- What doesn't? -->\n",
    "<!-- \n",
    "Note: â€œEmergent propertiesâ€ -> usually helpful automation, as long as there are constraints, but need to watch for weirdness and misalignment with what a legend would otherwise say a layer/category should look like\n",
    "\n",
    "(For instance, interpolation between color steps, etc) -->\n",
    "\n",
    "===\n",
    "\n",
    "# Processing pipeline\n",
    "\n",
    "1. **Download** - Fetch Overture Maps and GRID3 (AGOL feature services) data for specified extent (as GeoParquet file)\n",
    "2. **Convert to FlatGeobuf** - Transform GeoParquet to FlatGeobuf for compatibility + efficiency\n",
    "3. **Tile** - Generate PMTiles using tippecanoe with bespoke settings per-layer\n",
    "4. **View** - using maplibre open spec\n",
    "\n",
    "## File formats\n",
    "- **GeoParquet (.parquet)** - Download format (compact, fast queries via \"duckquery\")\n",
    "- **FlatGeobuf (.fgb)** - Convert for optimal tippecanoe library support\n",
    "- **GeoJSON (.geojson)** - Fallback support for small datasets\n",
    "- **pmTiles** - Dynamic vector tiles, served from single static file\n",
    "\n",
    "## CONFIG\n",
    "\n",
    ".env -> config.py imports environment vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e8a8ec",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded environment from repository root: c:\\Users\\mjh2241\\Documents\\GitHub\\.env\n",
      "  DATA_DISK = .\n",
      "\n",
      "=== EXTENT FROM ENVIRONMENT (.env) ===\n",
      "  West (lon_min):  12.19\n",
      "  South (lat_min): -13.46\n",
      "  East (lon_max):  31.31\n",
      "  North (lat_max): 5.39\n",
      "  Buffer (degrees): 0.5\n",
      "\n",
      "  Combined tuple: (12.19, -13.46, 31.31, 5.39)\n",
      "  Buffer: 0.5 degrees\n",
      "\n",
      "=== CONFIGURATION VERIFICATION ===\n",
      "Repository root:       c:\\Users\\mjh2241\\Documents\\GitHub\n",
      "Environment .env:      c:\\Users\\mjh2241\\Documents\\GitHub\\.env\n",
      "Environment DATA_DISK: .\n",
      "Config uses:           C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\n",
      "PROJECT CONFIGURATION\n",
      "============================================================\n",
      "Project root:        C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\1-processing\n",
      "Scripts directory:   C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\1-processing\\scripts\n",
      "Notebooks directory: C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\1-processing\\notebooks\n",
      "Data directory:      C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\data\n",
      "Scratch directory:   C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\data\\2-scratch\n",
      "Output directory:    C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\data\\3-pmtiles\n",
      "Overture data:       C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\data\\1-input\\overture\n",
      "GRID3 data:         C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\data\\1-input\\grid3\n",
      "\n",
      "Processing extent:   (12.19, -13.46, 31.31, 5.39)\n",
      "Buffer degrees:      0.5\n",
      "Area:                360.4120 degreeÂ² (~4440636 kmÂ²)\n",
      "============================================================\n",
      "\n",
      "=== DISK SPACE MANAGEMENT ===\n",
      "  Cleanup source files: True\n",
      "  â†’ Source .parquet files will be removed after successful .fgb conversion\n",
      "  â†’ FlatGeobuf (.fgb) files retained for fast PMTiles regeneration\n",
      "\n",
      "âœ“ Configuration loaded - CONFIG available in all cells\n",
      "\n",
      "âš ï¸  To change extent: Edit .env file and restart kernel\n",
      "   All downloads, processing, and viewing will use the same extent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\1-processing\\scripts\\generateLabels.py:37: UserWarning: centerline library not available. Install with: pip install centerline\n",
      "  warnings.warn(\"centerline library not available. Install with: pip install centerline\")\n",
      "c:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\1-processing\\scripts\\xgboost_optimizer.py:31: UserWarning: xgboost not available. Install with: pip install xgboost\n",
      "  warnings.warn(\"xgboost not available. Install with: pip install xgboost\")\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION - Run this cell first\n",
    "# ============================================================\n",
    "# This cell initializes all configuration and should be run \n",
    "# first. Re-run this cell to reload configuration changes.\n",
    "# ============================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Setup paths\n",
    "notebook_dir = Path.cwd()\n",
    "processing_dir = notebook_dir.parent  # 1-processing\n",
    "repo_root = processing_dir.parent     # basemap (repository root)\n",
    "\n",
    "# Add processing directory to path\n",
    "if str(processing_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(processing_dir))\n",
    "\n",
    "# Load environment variables from REPOSITORY ROOT (monorepo-wide .env)\n",
    "env_path = repo_root / '.env'\n",
    "load_dotenv(env_path)\n",
    "print(f\"âœ“ Loaded environment from repository root: {env_path}\")\n",
    "print(f\"  DATA_DISK = {os.environ.get('DATA_DISK', 'not set')}\")\n",
    "\n",
    "# Import configuration (will also load .env via config.py)\n",
    "from config import (\n",
    "    get_config,\n",
    "    ensure_directories,\n",
    "    print_config_summary,\n",
    "    SCRIPTS_DIR,\n",
    "    OUTPUT_DIR,\n",
    "    OVERTURE_DATA_DIR,\n",
    "    GRID3_DATA_DIR,\n",
    "    SCRATCH_DIR,\n",
    ")\n",
    "\n",
    "# Import processing functions\n",
    "from scripts import (\n",
    "    download_overture_data,\n",
    "    convert_file,\n",
    "    convert_parquet_to_fgb,\n",
    "    batch_convert_directory,\n",
    "    process_to_tiles,\n",
    "    create_tilejson,\n",
    "    download_arcgis_data,\n",
    "    batch_download_arcgis_layers,\n",
    ")\n",
    "\n",
    "# Additional libraries\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# GLOBAL CONFIGURATION - Available in all cells below\n",
    "# ============================================================\n",
    "CONFIG = get_config()\n",
    "\n",
    "# ============================================================\n",
    "# EXTENT CONFIGURATION - SINGLE SOURCE OF TRUTH\n",
    "# ============================================================\n",
    "# Extent is now configured in .env file (repository root)\n",
    "# To change the geographic area, edit .env and restart kernel\n",
    "# \n",
    "# Current extent values from .env:\n",
    "print(f\"\\n=== EXTENT FROM ENVIRONMENT (.env) ===\")\n",
    "print(f\"  West (lon_min):  {os.environ.get('EXTENT_WEST', 'not set')}\")\n",
    "print(f\"  South (lat_min): {os.environ.get('EXTENT_SOUTH', 'not set')}\")\n",
    "print(f\"  East (lon_max):  {os.environ.get('EXTENT_EAST', 'not set')}\")\n",
    "print(f\"  North (lat_max): {os.environ.get('EXTENT_NORTH', 'not set')}\")\n",
    "print(f\"  Buffer (degrees): {os.environ.get('EXTENT_BUFFER', 'not set')}\")\n",
    "print(f\"\\n  Combined tuple: {CONFIG['extent']['coordinates']}\")\n",
    "print(f\"  Buffer: {CONFIG['extent']['buffer_degrees']} degrees\")\n",
    "\n",
    "# DO NOT override extent here - edit .env instead!\n",
    "# CONFIG[\"extent\"][\"coordinates\"] is automatically loaded from .env\n",
    "\n",
    "# ============================================================\n",
    "# DISK SPACE MANAGEMENT\n",
    "# ============================================================\n",
    "# Automatically remove source files after successful conversion to save disk space\n",
    "# FlatGeobuf (.fgb) files are kept as intermediary files for fast PMTiles regeneration\n",
    "CONFIG[\"fgb_conversion\"][\"cleanup_source\"] = True  # Set to False to keep source files\n",
    "\n",
    "# Processing options (can still be customized here)\n",
    "CONFIG[\"tiling\"][\"input_dirs\"] = [SCRATCH_DIR]  # Read FlatGeobuf files from scratch\n",
    "CONFIG[\"download\"][\"verbose\"] = True\n",
    "CONFIG[\"conversion\"][\"verbose\"] = True\n",
    "CONFIG[\"tiling\"][\"verbose\"] = True\n",
    "CONFIG[\"tiling\"][\"parallel\"] = True\n",
    "\n",
    "# Create directories and verify\n",
    "ensure_directories()\n",
    "\n",
    "# Verification\n",
    "print(\"\\n=== CONFIGURATION VERIFICATION ===\")\n",
    "print(f\"Repository root:       {repo_root}\")\n",
    "print(f\"Environment .env:      {env_path}\")\n",
    "print(f\"Environment DATA_DISK: {os.environ.get('DATA_DISK', 'NOT SET')}\")\n",
    "print(f\"Config uses:           {CONFIG['paths']['data_dir'].parent}\")\n",
    "\n",
    "print_config_summary(CONFIG)\n",
    "\n",
    "# Disk management info\n",
    "print(\"\\n=== DISK SPACE MANAGEMENT ===\")\n",
    "print(f\"  Cleanup source files: {CONFIG['fgb_conversion']['cleanup_source']}\")\n",
    "if CONFIG['fgb_conversion']['cleanup_source']:\n",
    "    print(\"  â†’ Source .parquet files will be removed after successful .fgb conversion\")\n",
    "    print(\"  â†’ FlatGeobuf (.fgb) files retained for fast PMTiles regeneration\")\n",
    "else:\n",
    "    print(\"  â†’ Both .parquet and .fgb files will be kept\")\n",
    "\n",
    "print(\"\\nâœ“ Configuration loaded - CONFIG available in all cells\")\n",
    "print(\"\\nâš ï¸  To change extent: Edit .env file and restart kernel\")\n",
    "print(\"   All downloads, processing, and viewing will use the same extent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea97440",
   "metadata": {},
   "source": [
    "## 2. Download Overture Data with DuckDB \n",
    "\n",
    "Use the `downloadOverture.py` module to fetch geospatial data from Overture Maps\n",
    "\n",
    "e.g., replace periodic geofabrik OSM ~shapefile~ fetches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b170545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Overture Maps data\n",
    "print(\"=== STEP 1: DOWNLOADING OVERTURE DATA ===\")\n",
    "download_results = download_overture_data(\n",
    "    extent=CONFIG[\"extent\"][\"coordinates\"],\n",
    "    buffer_degrees=CONFIG[\"extent\"][\"buffer_degrees\"],\n",
    "    template_path=str(CONFIG[\"paths\"][\"template_path\"]),\n",
    "    verbose=CONFIG[\"download\"][\"verbose\"],\n",
    "    project_root=str(CONFIG[\"paths\"][\"project_root\"]),\n",
    "    overture_data_dir=str(CONFIG[\"paths\"][\"overture_data_dir\"])\n",
    ")\n",
    "\n",
    "print(f\"Download completed: {download_results['success']}\")\n",
    "print(f\"Sections processed: {download_results['processed_sections']}\")\n",
    "if download_results[\"errors\"]:\n",
    "    print(f\"Errors encountered: {len(download_results['errors'])}\")\n",
    "    for error in download_results[\"errors\"]:\n",
    "        print(f\"  - {error}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615202ce",
   "metadata": {},
   "source": [
    "## Overture Maps Cartography Properties\n",
    "\n",
    "The updated DuckDB queries now extract **cartography** and **level** properties from Overture Maps data (2025-11-19.0 release):\n",
    "\n",
    "### Cartography Container (base theme layers)\n",
    "Available in: `land_cover`, `land_use`, `water`, `land`, `infrastructure`\n",
    "\n",
    "- **`min_zoom`** - Recommended minimum zoom level for displaying this feature\n",
    "- **`max_zoom`** - Recommended maximum zoom level for displaying this feature  \n",
    "- **`sort_key`** - Z-ordering priority for rendering (higher values draw on top)\n",
    "\n",
    "### Level Property\n",
    "Available in: Most base theme layers, buildings, infrastructure\n",
    "\n",
    "- **`level`** - Vertical level/floor number for multi-level features\n",
    "- Used for proper z-ordering in buildings and infrastructure\n",
    "- Enables floor-aware filtering and visualization\n",
    "\n",
    "### How These Properties Are Used\n",
    "\n",
    "**1. During Tiling (`tippecanoe.py`):**\n",
    "- `extract_cartography_zoom_range()` reads cartography properties from input files\n",
    "- Automatically applies optimal zoom ranges to each layer\n",
    "- `sort_key` and `level` are preserved in PMTiles for renderer use\n",
    "\n",
    "**2. In the Map Viewer (`basemap.js`):**\n",
    "- Properties are available as feature attributes in PMTiles\n",
    "- Can be used in MapLibre style expressions for:\n",
    "  - Zoom-dependent filtering: `[\">=\", [\"zoom\"], [\"get\", \"min_zoom\"]]`\n",
    "  - Z-ordering: `[\"get\", \"sort_key\"]` in `symbol-sort-key`\n",
    "  - Floor filtering: `[\"==\", [\"get\", \"level\"], 0]`\n",
    "  - Dynamic styling based on feature importance\n",
    "\n",
    "**3. Benefits:**\n",
    "- More efficient tiles (features only at appropriate zoom levels)\n",
    "- Better rendering performance (proper z-ordering reduces overdraw)\n",
    "- Richer data model (multi-level buildings, elevation-aware features)\n",
    "- Aligned with Overture's cartographic recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd9b6c9",
   "metadata": {},
   "source": [
    "### What Changed in the Pipeline\n",
    "\n",
    "**âœ… Updated: `tileQueries.sql`**\n",
    "- Added `level` property to `land_cover` query (was missing)\n",
    "- Added cartography properties (`min_zoom`, `max_zoom`, `sort_key`) to:\n",
    "  - `land_use` (both residential and non-residential)\n",
    "  - `water`\n",
    "  - `land`\n",
    "  - `infrastructure`\n",
    "\n",
    "**âœ… Updated: `tippecanoe.py`**\n",
    "- Enhanced documentation for `extract_cartography_zoom_range()` to mention level and sort_key\n",
    "- Updated `build_tippecanoe_command()` docstring to explain how properties are preserved\n",
    "\n",
    "**âœ… No changes needed:**\n",
    "- `convertToFlatGeobuf.py` - Already preserves all attributes automatically\n",
    "- `downloadOverture.py` - No changes needed (uses SQL template)\n",
    "- Conversion pipeline - Properties flow through automatically\n",
    "\n",
    "**Result:** All Overture Maps cartography properties are now extracted, preserved, and available in your PMTiles for use in MapLibre styles!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f11f7c",
   "metadata": {},
   "source": [
    "## 2a. Download ArcGIS Feature Server Data\n",
    "\n",
    "Download geospatial data from hosted ArcGIS Feature Server REST API endpoints - can include any esri-hosted data as endpoint\n",
    "\n",
    "- **Automatic pagination** - Handles ArcGIS's 1000-2000 feature limit per request\n",
    "- **Spatial filtering** - Apply bounding box filter to download only features in aoi\n",
    "- **formats** - Download as GeoJSON or directly convert to FlatGeobuf\n",
    "- **Batch processing** - Download multiple layers with one function call\n",
    "\n",
    "### GRID3 DRC Layers\n",
    "- https://services3.arcgis.com/BU6Aadhn6tbBEdyk/arcgis/rest/services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0085a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 2a: DOWNLOADING ARCGIS DATA (OPTIONAL) ===\n",
      "Using extent from CONFIG: (12.19, -13.46, 31.31, 5.39)\n",
      "  Longitude: 12.19 to 31.31\n",
      "  Latitude: -13.46 to 5.39\n",
      "\n",
      "============================================================\n",
      "Processing: settlement_extents\n",
      "============================================================\n",
      "Downloading from ArcGIS Feature Server...\n",
      "  URL: https://services3.arcgis.com/BU6Aadhn6tbBEdyk/arcgis/rest/services/GRID3_COD_Settlement_Extents_v3_1/FeatureServer/0\n",
      "  Extent: (12.19, -13.46, 31.31, 5.39)\n",
      "  Output: C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\data\\2-scratch\\settlement_extents.fgb\n",
      "  Format: fgb\n",
      "Total features to download: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading features: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0 features\n",
      "\n",
      "============================================================\n",
      "Processing: health_zones\n",
      "============================================================\n",
      "Downloading from ArcGIS Feature Server...\n",
      "  URL: https://services3.arcgis.com/BU6Aadhn6tbBEdyk/arcgis/rest/services/GRID3_COD_health_zones_v7_0/FeatureServer/0\n",
      "  Extent: (12.19, -13.46, 31.31, 5.39)\n",
      "  Output: C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\data\\2-scratch\\health_zones.fgb\n",
      "  Format: fgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features to download: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading features: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0 features\n",
      "\n",
      "============================================================\n",
      "Processing: health_areas\n",
      "============================================================\n",
      "Downloading from ArcGIS Feature Server...\n",
      "  URL: https://services3.arcgis.com/BU6Aadhn6tbBEdyk/ArcGIS/rest/services/GRID3_COD_health_areas_v7_0/FeatureServer/0\n",
      "  Extent: (12.19, -13.46, 31.31, 5.39)\n",
      "  Output: C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\data\\2-scratch\\health_areas.fgb\n",
      "  Format: fgb\n",
      "Total features to download: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading features: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0 features\n",
      "\n",
      "============================================================\n",
      "Processing: settlement_names\n",
      "============================================================\n",
      "Downloading from ArcGIS Feature Server...\n",
      "  URL: https://services3.arcgis.com/BU6Aadhn6tbBEdyk/ArcGIS/rest/services/GRID3_COD_settlement_names_v7_0/FeatureServer/0\n",
      "  Extent: (12.19, -13.46, 31.31, 5.39)\n",
      "  Output: C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\data\\2-scratch\\settlement_names.fgb\n",
      "  Format: fgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features to download: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading features: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0 features\n",
      "\n",
      "============================================================\n",
      "Processing: health_facilities\n",
      "============================================================\n",
      "Downloading from ArcGIS Feature Server...\n",
      "  URL: https://services3.arcgis.com/BU6Aadhn6tbBEdyk/ArcGIS/rest/services/COD_GRID3_health_facilities_v7_0/FeatureServer/0\n",
      "  Extent: (12.19, -13.46, 31.31, 5.39)\n",
      "  Output: C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\data\\2-scratch\\health_facilities.fgb\n",
      "  Format: fgb\n",
      "Total features to download: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading features: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0 features\n",
      "\n",
      "============================================================\n",
      "Processing: religious_centers\n",
      "============================================================\n",
      "Downloading from ArcGIS Feature Server...\n",
      "  URL: https://services3.arcgis.com/BU6Aadhn6tbBEdyk/ArcGIS/rest/services/GRID3_COD_religious_centers_v1_0/FeatureServer/0\n",
      "  Extent: (12.19, -13.46, 31.31, 5.39)\n",
      "  Output: C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\data\\2-scratch\\religious_centers.fgb\n",
      "  Format: fgb\n",
      "Total features to download: 22,627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22627/22627 [00:13<00:00, 1688.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 22,627 features\n",
      "Converting to FlatGeobuf...\n",
      "âœ“ Saved 22,627 features to C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\data\\2-scratch\\religious_centers.fgb\n",
      "\n",
      "============================================================\n",
      "BATCH DOWNLOAD SUMMARY\n",
      "============================================================\n",
      "Total layers: 6\n",
      "Successful: 1\n",
      "Failed: 5\n",
      "\n",
      "ArcGIS Download Summary:\n",
      "  Total layers: 6\n",
      "  Successful: 1\n",
      "  Failed: 5\n",
      "  âœ— settlement_extents: No features downloaded\n",
      "  âœ— health_zones: No features downloaded\n",
      "  âœ— health_areas: No features downloaded\n",
      "  âœ— settlement_names: No features downloaded\n",
      "  âœ— health_facilities: No features downloaded\n",
      "  âœ“ religious_centers: 22,627 features\n"
     ]
    }
   ],
   "source": [
    "# Download ArcGIS Feature Server data (optional - skip if not needed)\n",
    "print(\"=== STEP 2a: DOWNLOADING ARCGIS DATA (OPTIONAL) ===\")\n",
    "print(f\"Using extent from CONFIG: {CONFIG['extent']['coordinates']}\")\n",
    "print(f\"  Longitude: {CONFIG['extent']['coordinates'][0]} to {CONFIG['extent']['coordinates'][2]}\")\n",
    "print(f\"  Latitude: {CONFIG['extent']['coordinates'][1]} to {CONFIG['extent']['coordinates'][3]}\")\n",
    "\n",
    "# Define ArcGIS layers to download\n",
    "# Uncomment and customize the layers you need\n",
    "arcgis_layers = [\n",
    "    {\n",
    "        'url': 'https://services3.arcgis.com/BU6Aadhn6tbBEdyk/arcgis/rest/services/GRID3_COD_Settlement_Extents_v3_1/FeatureServer/0',\n",
    "        'name': 'settlement_extents',\n",
    "        'where': '1=1'\n",
    "    },\n",
    "    {\n",
    "        'url': 'https://services3.arcgis.com/BU6Aadhn6tbBEdyk/arcgis/rest/services/GRID3_COD_health_zones_v7_0/FeatureServer/0',\n",
    "        'name': 'health_zones',\n",
    "        'where': '1=1'  # Download all features (can add SQL filter here)\n",
    "    },\n",
    "    {\n",
    "        'url': 'https://services3.arcgis.com/BU6Aadhn6tbBEdyk/ArcGIS/rest/services/GRID3_COD_health_areas_v7_0/FeatureServer/0',\n",
    "        'name': 'health_areas',\n",
    "        'where': '1=1'\n",
    "    },\n",
    "        {\n",
    "        'url': 'https://services3.arcgis.com/BU6Aadhn6tbBEdyk/ArcGIS/rest/services/GRID3_COD_settlement_names_v7_0/FeatureServer/0',\n",
    "        'name': 'settlement_names',\n",
    "        'where': '1=1'  \n",
    "    },\n",
    "    {\n",
    "        'url': 'https://services3.arcgis.com/BU6Aadhn6tbBEdyk/ArcGIS/rest/services/COD_GRID3_health_facilities_v7_0/FeatureServer/0',\n",
    "        'name': 'health_facilities',\n",
    "        'where': '1=1'\n",
    "    },\n",
    "    {\n",
    "        'url': 'https://services3.arcgis.com/BU6Aadhn6tbBEdyk/ArcGIS/rest/services/GRID3_COD_religious_centers_v1_0/FeatureServer/0',\n",
    "        'name': 'religious_centers',\n",
    "        'where': '1=1'\n",
    "    },\n",
    "]\n",
    "\n",
    "# Download layers using the SAME EXTENT as Overture data\n",
    "# This ensures all data layers align spatially\n",
    "if arcgis_layers:\n",
    "    arcgis_results = batch_download_arcgis_layers(\n",
    "        layer_configs=arcgis_layers,\n",
    "        output_dir=str(CONFIG[\"paths\"][\"scratch_dir\"]),  # Save directly to scratch for tiling\n",
    "        extent=CONFIG[\"extent\"][\"coordinates\"],  # â† SAME EXTENT as Overture downloads\n",
    "        output_format=\"fgb\",  # Use FlatGeobuf for optimal tiling performance\n",
    "        verbose=CONFIG[\"download\"][\"verbose\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nArcGIS Download Summary:\")\n",
    "    print(f\"  Total layers: {arcgis_results['total_layers']}\")\n",
    "    print(f\"  Successful: {arcgis_results['successful']}\")\n",
    "    print(f\"  Failed: {arcgis_results['failed']}\")\n",
    "    \n",
    "    for layer in arcgis_results['layers']:\n",
    "        if layer['success']:\n",
    "            print(f\"  âœ“ {layer['name']}: {layer['feature_count']:,} features\")\n",
    "        else:\n",
    "            print(f\"  âœ— {layer['name']}: {layer.get('error', 'Unknown error')}\")\n",
    "else:\n",
    "    print(\"No ArcGIS layers configured. Edit arcgis_layers list above to download data.\")\n",
    "    print(f\"\\nNote: When configured, downloads will use extent: {CONFIG['extent']['coordinates']}\")\n",
    "\n",
    "# Option 2: Download a single layer (alternative approach)\n",
    "# Also uses the same extent from CONFIG\n",
    "# Uncomment and customize as needed:\n",
    "# single_layer_result = download_arcgis_data(\n",
    "#     service_url='https://services3.arcgis.com/BU6Aadhn6tbBEdyk/arcgis/rest/services/GRID3_COD_health_zones_v7_0/FeatureServer/0',\n",
    "#     output_path=str(CONFIG[\"paths\"][\"scratch_dir\"] / \"health_zones.fgb\"),\n",
    "#     extent=CONFIG[\"extent\"][\"coordinates\"],  # â† Uses CONFIG extent\n",
    "#     output_format=\"fgb\",\n",
    "#     verbose=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3aabc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate centroids for administrative boundary labels\n",
    "print(\"=== STEP 2b: GENERATING CENTROIDS FOR ADMINISTRATIVE LABELS ===\")\n",
    "\n",
    "# Import the centroid generation function\n",
    "from scripts import batch_generate_centroids\n",
    "\n",
    "# Define which layers need centroids for label positioning\n",
    "# These correspond to the administrative boundary layers\n",
    "layers_for_centroids = [\n",
    "    'health_zones',   # Health zone polygons -> health_zones_centroids\n",
    "    'health_areas',   # Health area polygons -> health_areas_centroids\n",
    "]\n",
    "\n",
    "# Generate centroids for specified layers\n",
    "# NOTE: Centroids now include 'label_rotation' attribute for best-fit text orientation\n",
    "# The rotation angle is calculated from the minimum rotated rectangle of each polygon\n",
    "centroid_results = batch_generate_centroids(\n",
    "    input_dir=str(CONFIG[\"paths\"][\"scratch_dir\"]),  # Where polygon FGB files are\n",
    "    output_dir=str(CONFIG[\"paths\"][\"scratch_dir\"]),  # Save centroids alongside polygons\n",
    "    layers=layers_for_centroids,                     # Only process these layers\n",
    "    suffix='_centroids',                             # Output: layer_name_centroids.fgb\n",
    "    verbose=CONFIG[\"download\"][\"verbose\"]\n",
    ")\n",
    "\n",
    "print(f\"\\nCentroid Generation Summary:\")\n",
    "print(f\"  Total layers: {centroid_results['total_layers']}\")\n",
    "print(f\"  Successful: {centroid_results['successful']}\")\n",
    "print(f\"  Failed: {centroid_results['failed']}\")\n",
    "print(f\"  Note: Each centroid includes 'label_rotation' for best-fit orientation\")\n",
    "\n",
    "for layer in centroid_results['layers']:\n",
    "    if layer['success']:\n",
    "        output_name = Path(layer['output_file']).name\n",
    "        print(f\"  âœ“ {output_name}: {layer['feature_count']:,} centroids\")\n",
    "    else:\n",
    "        print(f\"  âœ— {Path(layer['input_file']).name}: {layer.get('error', 'Unknown error')}\")\n",
    "\n",
    "# List all files ready for tiling (including new centroids)\n",
    "if CONFIG[\"paths\"][\"scratch_dir\"].exists():\n",
    "    all_fgb_files = sorted(CONFIG[\"paths\"][\"scratch_dir\"].glob(\"*.fgb\"))\n",
    "    centroid_files = [f for f in all_fgb_files if '_centroids' in f.name]\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Files ready for tiling:\")\n",
    "    print(f\"  Total FlatGeobuf files: {len(all_fgb_files)}\")\n",
    "    print(f\"  Centroid files: {len(centroid_files)}\")\n",
    "    if centroid_files:\n",
    "        for f in centroid_files:\n",
    "            print(f\"    - {f.name}\")\n",
    "    print(f\"  Location: {CONFIG['paths']['scratch_dir']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee605ffe",
   "metadata": {},
   "source": [
    "## 2b. Generate Centroids for Administrative Polygons\n",
    "\n",
    "Generate interior centroid points for health zones and health areas. These will be used for single-label-per-polygon rendering in the map viewer (interior labels at lower zoom levels).\n",
    "\n",
    "**Why centroids?**\n",
    "- Guarantees one label per polygon (no duplicates across tile boundaries)\n",
    "- `representative_point()` ensures label is always inside the polygon\n",
    "- Preserves all attributes for label content\n",
    "- Separate point layer is more efficient than point-based symbol placement on polygons\n",
    "\n",
    "**NEW: Label Rotation for Best-Fit**\n",
    "- Each centroid now includes a `label_rotation` attribute (in degrees)\n",
    "- Calculated from the minimum rotated rectangle (oriented bounding box) of each polygon\n",
    "- Labels rotate to align with the polygon's longest axis\n",
    "- Ensures labels fit naturally within elongated or diagonal polygons\n",
    "- Rotation range: -90Â° to +90Â° (text never appears upside down)\n",
    "\n",
    "**Map Style Integration:**\n",
    "The viewer style uses:\n",
    "- `\"text-rotation-alignment\": \"map\"` - Rotates with map, not viewport\n",
    "- `\"text-rotate\": [\"get\", \"label_rotation\"]` - Uses the calculated rotation angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ac49f",
   "metadata": {},
   "source": [
    "## 2c. Generate Centerlines for Water Polygons\n",
    "\n",
    "Generate centerline features for polygonal water bodies (lakes, reservoirs, etc.). These will be used for placing labels along the natural axis of elongated water features.\n",
    "\n",
    "**Why centerlines?**\n",
    "- Better label placement for elongated water features (lakes, reservoirs)\n",
    "- Creates linear features along the medial axis of polygons\n",
    "- Labels follow the natural orientation of the water body\n",
    "- Uses Voronoi-based skeleton algorithm for accurate centerline extraction\n",
    "- Preserves all attributes for label content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceaa205",
   "metadata": {},
   "source": [
    "# temp: markdown start here\n",
    "# Generate centerlines for water feature labels\n",
    "print(\"=== STEP 2c: GENERATING CENTERLINES FOR WATER LABELS ===\")\n",
    "\n",
    "# Import the centerline generation function\n",
    "from scripts import batch_generate_centerlines\n",
    "\n",
    "# Define which layers need centerlines for label positioning\n",
    "# Typically used for elongated water bodies like lakes and reservoirs\n",
    "layers_for_centerlines = [\n",
    "    'water',  # Water polygons -> water_centerlines\n",
    "]\n",
    "\n",
    "# Generate centerlines for specified layers\n",
    "centerline_results = batch_generate_centerlines(\n",
    "    input_dir=str(CONFIG[\"paths\"][\"scratch_dir\"]),  # Where polygon FGB files are\n",
    "    output_dir=str(CONFIG[\"paths\"][\"scratch_dir\"]),  # Save centerlines alongside polygons\n",
    "    layers=layers_for_centerlines,                   # Only process these layers\n",
    "    suffix='_centerlines',                           # Output: layer_name_centerlines.fgb\n",
    "    simplify_tolerance=5.0,                          # N meters simplification\n",
    "    border_density=20,                            # Increase this for winding rivers (default is 100)\n",
    "    verbose=CONFIG[\"download\"][\"verbose\"]\n",
    ")\n",
    "\n",
    "print(f\"  Total layers: {centerline_results['total_layers']}\")\n",
    "print(f\"  Successful: {centerline_results['successful']}\")\n",
    "print(f\"  Failed: {centerline_results['failed']}\")\n",
    "\n",
    "for layer in centerline_results['layers']:\n",
    "    if layer['success']:\n",
    "        output_name = Path(layer['output_file']).name\n",
    "        print(f\"  âœ“ {output_name}: {layer['feature_count']:,} centerlines\")\n",
    "    else:\n",
    "        print(f\"  âœ— {Path(layer['input_file']).name}: {layer.get('error', 'Unknown error')}\")\n",
    "\n",
    "# List all processed files ready for tiling\n",
    "if CONFIG[\"paths\"][\"scratch_dir\"].exists():\n",
    "    all_fgb_files = sorted(CONFIG[\"paths\"][\"scratch_dir\"].glob(\"*.fgb\"))\n",
    "    centroid_files = [f for f in all_fgb_files if '_centroids' in f.name]\n",
    "    centerline_files = [f for f in all_fgb_files if '_centerlines' in f.name]\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processed geometry files ready for tiling:\")\n",
    "    print(f\"  Total FlatGeobuf files: {len(all_fgb_files)}\")\n",
    "    print(f\"  Centroid files: {len(centroid_files)}\")\n",
    "    if centroid_files:\n",
    "        for f in centroid_files:\n",
    "            print(f\"    - {f.name}\")\n",
    "    print(f\"  Centerline files: {len(centerline_files)}\")\n",
    "    if centerline_files:\n",
    "        for f in centerline_files:\n",
    "            print(f\"    - {f.name}\")\n",
    "    print(f\"  Location: {CONFIG['paths']['scratch_dir']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a64ae5",
   "metadata": {},
   "source": [
    "### ArcGIS Feature Server Downloads\n",
    "\n",
    "**Finding Feature Server URLs:**\n",
    "1. Browse your organization's ArcGIS REST Services Directory\n",
    "2. Navigate to a specific layer (e.g., FeatureServer/0, FeatureServer/1)\n",
    "3. Copy the full URL up to and including the layer number\n",
    "4. The script will automatically append `/query` and handle parameters\n",
    "\n",
    "**Spatial Filtering:**\n",
    "- The `extent` parameter filters features to your bounding box (saves bandwidth & time)\n",
    "- For global layers, omit `extent=None` to download all features\n",
    "- Extent uses WGS84 coordinates: `(lon_min, lat_min, lon_max, lat_max)`\n",
    "\n",
    "**Attribute Filtering:**\n",
    "- Use `where` clause for SQL-based filtering: `'population > 10000'`\n",
    "- Default `'1=1'` downloads all features\n",
    "\n",
    "**Output Formats:**\n",
    "- `\"fgb\"` (FlatGeobuf) - Recommended for direct tiling (streaming, indexed)\n",
    "- `\"geojson\"` - more flexible, less optimal\n",
    "\n",
    "\n",
    "- Large datasets (>100k features) automatically use pagination\n",
    "- Downloads directly to scratch directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what files were created during download\n",
    "print(\"=== CHECKING DOWNLOADED FILES ===\")\n",
    "\n",
    "# Check Overture Maps downloads (GeoParquet)\n",
    "overture_files = []\n",
    "search_dirs = [CONFIG[\"paths\"][\"data_dir\"], CONFIG[\"paths\"][\"overture_data_dir\"]]\n",
    "\n",
    "for data_dir in search_dirs:\n",
    "    if data_dir.exists():\n",
    "        for pattern in CONFIG[\"download\"][\"output_formats\"]:\n",
    "            files = list(data_dir.glob(pattern))\n",
    "            overture_files.extend(files)\n",
    "\n",
    "print(f\"\\nOverture Maps (GeoParquet): {len(overture_files)} files\")\n",
    "overture_size_mb = 0\n",
    "for file in sorted(overture_files):\n",
    "    file_size = file.stat().st_size / 1024 / 1024  # Size in MB\n",
    "    overture_size_mb += file_size\n",
    "    print(f\"  {file.name} ({file_size:.1f} MB)\")\n",
    "\n",
    "# Check FlatGeobuf files in scratch\n",
    "fgb_files = []\n",
    "if CONFIG[\"paths\"][\"scratch_dir\"].exists():\n",
    "    fgb_files = list(CONFIG[\"paths\"][\"scratch_dir\"].glob(\"*.fgb\"))\n",
    "\n",
    "print(f\"\\nFlatGeobuf (Scratch): {len(fgb_files)} files\")\n",
    "fgb_size_mb = 0\n",
    "for file in sorted(fgb_files):\n",
    "    file_size = file.stat().st_size / 1024 / 1024  # Size in MB\n",
    "    fgb_size_mb += file_size\n",
    "    print(f\"  {file.name} ({file_size:.1f} MB)\")\n",
    "\n",
    "# Check PMTiles\n",
    "pmtiles_files = []\n",
    "if CONFIG[\"paths\"][\"tile_dir\"].exists():\n",
    "    pmtiles_files = list(CONFIG[\"paths\"][\"tile_dir\"].glob(\"*.pmtiles\"))\n",
    "\n",
    "print(f\"\\nPMTiles (Output): {len(pmtiles_files)} files\")\n",
    "pmtiles_size_mb = 0\n",
    "for file in sorted(pmtiles_files):\n",
    "    file_size = file.stat().st_size / 1024 / 1024  # Size in MB\n",
    "    pmtiles_size_mb += file_size\n",
    "    print(f\"  {file.name} ({file_size:.1f} MB)\")\n",
    "\n",
    "# Display overall statistics\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"DISK USAGE SUMMARY\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"  Overture GeoParquet: {overture_size_mb:.1f} MB ({len(overture_files)} files)\")\n",
    "print(f\"  FlatGeobuf:          {fgb_size_mb:.1f} MB ({len(fgb_files)} files)\")\n",
    "print(f\"  PMTiles:             {pmtiles_size_mb:.1f} MB ({len(pmtiles_files)} files)\")\n",
    "print(f\"  Total:               {overture_size_mb + fgb_size_mb + pmtiles_size_mb:.1f} MB\")\n",
    "\n",
    "if CONFIG[\"fgb_conversion\"][\"cleanup_source\"]:\n",
    "    print(f\"\\n  Cleanup enabled: Source .parquet files will be removed after conversion\")\n",
    "    if overture_files:\n",
    "        print(f\"  Potential savings: ~{overture_size_mb:.1f} MB\")\n",
    "else:\n",
    "    print(f\"\\n  Cleanup disabled: All intermediate files retained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a89d40a",
   "metadata": {},
   "source": [
    "## 3. Convert GeoParquet to FlatGeobuf\n",
    "\n",
    "Convert downloaded Overture GeoParquet files to FlatGeobuf format for tippecanoe compatibility\n",
    "\n",
    "**Note**: ArcGIS data was already downloaded as FlatGeobuf in Step 2a, so this step only processes Overture Maps data. Both sources will coexist in the scratch directory.\n",
    "\n",
    "### Disk Space Management\n",
    "\n",
    "**Automatic cleanup enabled**: Source `.parquet` files are automatically removed after successful conversion to save disk space.\n",
    "\n",
    "**Why this works:**\n",
    "- **FlatGeobuf files (.fgb)** are retained as intermediary files\n",
    "- PMTiles can be quickly regenerated from .fgb files anytime\n",
    "- .fgb files are ~30-50% smaller than .parquet\n",
    "- Conversion from .fgb â†’ .pmtiles is faster than .parquet â†’ .pmtiles\n",
    "\n",
    "**Workflow:**\n",
    "```\n",
    "Download (.parquet)  â†’  Convert (.fgb)  â†’  Delete (.parquet)  â†’  Tile (.pmtiles)\n",
    "                              â†“                                         â†‘\n",
    "                         [KEPT FOR]  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        Re-tiling anytime\n",
    "```\n",
    "\n",
    "**To disable cleanup:** Set `cleanup_source=False` in the conversion step below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153cffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that downloaded data extent matches configured extent\n",
    "print(\"=== EXTENT VERIFICATION ===\")\n",
    "\n",
    "# Get configured extent from CONFIG (loaded from .env)\n",
    "config_extent = CONFIG[\"extent\"][\"coordinates\"]\n",
    "config_west, config_south, config_east, config_north = config_extent\n",
    "\n",
    "print(f\"\\n1. Configured Extent (from .env):\")\n",
    "print(f\"   West:  {config_west:>10.6f}\")\n",
    "print(f\"   South: {config_south:>10.6f}\")\n",
    "print(f\"   East:  {config_east:>10.6f}\")\n",
    "print(f\"   North: {config_north:>10.6f}\")\n",
    "\n",
    "# Check actual extent of downloaded files\n",
    "import subprocess\n",
    "\n",
    "def get_fgb_extent(file_path):\n",
    "    \"\"\"Get extent from FlatGeobuf file using ogrinfo\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['ogrinfo', '-al', '-so', str(file_path)],\n",
    "            capture_output=True, text=True, timeout=10\n",
    "        )\n",
    "        for line in result.stdout.split('\\n'):\n",
    "            if 'Extent:' in line:\n",
    "                # Parse: Extent: (20.294878, -7.704176) - (23.705435, -3.795773)\n",
    "                parts = line.split(':')[1].strip()\n",
    "                parts = parts.replace('(', '').replace(')', '').replace(' - ', ',')\n",
    "                coords = [float(x.strip()) for x in parts.split(',')]\n",
    "                return tuple(coords)  # (west, south, east, north)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "# Check key files\n",
    "check_files = ['buildings.fgb', 'roads.fgb', 'water.fgb']\n",
    "mismatches = []\n",
    "\n",
    "print(f\"\\n2. Downloaded Data Extents:\")\n",
    "for filename in check_files:\n",
    "    fgb_path = CONFIG[\"paths\"][\"scratch_dir\"] / filename\n",
    "    if fgb_path.exists():\n",
    "        extent = get_fgb_extent(fgb_path)\n",
    "        if extent:\n",
    "            west, south, east, north = extent\n",
    "            print(f\"\\n   {filename}:\")\n",
    "            print(f\"     West:  {west:>10.6f}\")\n",
    "            print(f\"     South: {south:>10.6f}\")\n",
    "            print(f\"     East:  {east:>10.6f}\")\n",
    "            print(f\"     North: {north:>10.6f}\")\n",
    "            \n",
    "            # Check if extents match (within 0.5 degree tolerance for tile snapping)\n",
    "            tolerance = 0.5\n",
    "            west_match = abs(west - config_west) < tolerance\n",
    "            south_match = abs(south - config_south) < tolerance\n",
    "            east_match = abs(east - config_east) < tolerance\n",
    "            north_match = abs(north - config_north) < tolerance\n",
    "            \n",
    "            if not (west_match and south_match and east_match and north_match):\n",
    "                mismatches.append({\n",
    "                    'file': filename,\n",
    "                    'data_extent': extent,\n",
    "                    'config_extent': config_extent\n",
    "                })\n",
    "    else:\n",
    "        print(f\"\\n   {filename}: Not found\")\n",
    "\n",
    "# Report results\n",
    "print(f\"\\n{'='*60}\")\n",
    "if mismatches:\n",
    "    print(\"EXTENT MISMATCH DETECTED!\")\n",
    "    print(f\"\\n   {len(mismatches)} file(s) have different extents than configured.\")\n",
    "    print(f\"\\n   SOLUTION:\")\n",
    "    print(f\"   1. If you want the data in the downloaded files:\")\n",
    "    print(f\"      - Update EXTENT_* values in .env to match data extent\")\n",
    "    print(f\"      - Restart kernel and re-run cells\")\n",
    "    print(f\"\\n   2. If you want the extent currently in .env:\")\n",
    "    print(f\"      - Delete files: {CONFIG['paths']['scratch_dir']}\")\n",
    "    print(f\"      - Delete files: {CONFIG['paths']['overture_data_dir']}\")\n",
    "    print(f\"      - Re-run download cells (Step 1 and 2a)\")\n",
    "    print(f\"\\n   DO NOT proceed to tiling until extents match!\")\n",
    "else:\n",
    "    print(\"EXTENT VERIFICATION PASSED\")\n",
    "    print(f\"\\n   All downloaded data matches the configured extent.\")\n",
    "    print(f\"   Safe to proceed with tile generation.\")\n",
    "print(f\"{'='*60}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030782fb",
   "metadata": {},
   "source": [
    "## 2.5b. Verify Extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert GeoParquet files to FlatGeobuf for optimal tiling performance\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ”„ STEP 3: CONVERTING OVERTURE GEOPARQUET TO FLATGEOBUF\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nâ„¹ï¸  Note: ArcGIS data already in FlatGeobuf format (from Step 2a)\")\n",
    "print(f\"ðŸ§¹ Cleanup: {'ENABLED' if CONFIG['fgb_conversion']['cleanup_source'] else 'DISABLED'}\")\n",
    "\n",
    "# Get list of existing ArcGIS FlatGeobuf files to avoid overwriting\n",
    "existing_fgb_files = set()\n",
    "if CONFIG[\"paths\"][\"scratch_dir\"].exists():\n",
    "    existing_fgb_files = {f.stem for f in CONFIG[\"paths\"][\"scratch_dir\"].glob(\"*.fgb\")}\n",
    "    if existing_fgb_files:\n",
    "        print(f\"\\nâœ“ Preserving {len(existing_fgb_files)} existing ArcGIS FlatGeobuf files:\")\n",
    "        for name in sorted(list(existing_fgb_files)[:5]):  # Show first 5\n",
    "            print(f\"  â€¢ {name}.fgb\")\n",
    "        if len(existing_fgb_files) > 5:\n",
    "            print(f\"  ... and {len(existing_fgb_files) - 5} more\")\n",
    "\n",
    "# Convert Overture GeoParquet files to FlatGeobuf\n",
    "# STREAMING ENABLED: Automatically uses Polars streaming for large files (>500MB)\n",
    "# CLEANUP: Source .parquet files removed after successful conversion (saves disk space)\n",
    "# The .fgb intermediary files are kept for efficient PMTiles regeneration\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "fgb_results = batch_convert_directory(\n",
    "    input_dir=str(CONFIG[\"paths\"][\"overture_data_dir\"]),\n",
    "    output_dir=str(CONFIG[\"paths\"][\"scratch_dir\"]),\n",
    "    pattern=CONFIG[\"fgb_conversion\"][\"input_pattern\"],\n",
    "    overwrite=CONFIG[\"fgb_conversion\"][\"overwrite\"],\n",
    "    verbose=CONFIG[\"fgb_conversion\"][\"verbose\"],\n",
    "    cleanup_source=CONFIG[\"fgb_conversion\"][\"cleanup_source\"]\n",
    ")\n",
    "\n",
    "# The module now prints a detailed summary automatically when verbose=True\n",
    "# No need for duplicate summary here\n",
    "\n",
    "# Count total FlatGeobuf files ready for tiling\n",
    "if CONFIG[\"paths\"][\"scratch_dir\"].exists():\n",
    "    all_fgb_files = list(CONFIG[\"paths\"][\"scratch_dir\"].glob(\"*.fgb\"))\n",
    "    overture_fgb_count = len([f for f in all_fgb_files if f.stem not in existing_fgb_files])\n",
    "    arcgis_fgb_count = len(existing_fgb_files)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"ALL FLATGEOBUF FILES READY FOR TILING\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"  Location: {CONFIG['paths']['scratch_dir']}\")\n",
    "    print(f\"  Total files: {len(all_fgb_files)}\")\n",
    "    print(f\"     â€¢ Overture (converted): {overture_fgb_count}\")\n",
    "    print(f\"     â€¢ ArcGIS (direct): {arcgis_fgb_count}\")\n",
    "    \n",
    "    if CONFIG[\"fgb_conversion\"][\"cleanup_source\"]:\n",
    "        print(f\"\\n  â„¹  Source .parquet files removed to save disk space\")\n",
    "        print(f\"     FlatGeobuf files retained for efficient PMTiles regeneration\")\n",
    "    \n",
    "    # Show file listing\n",
    "    print(f\"\\n  Files:\")\n",
    "    for f in sorted(all_fgb_files)[:10]:  # Show first 10\n",
    "        size_mb = f.stat().st_size / 1024 / 1024\n",
    "        print(f\"     â€¢ {f.name} ({size_mb:.1f} MB)\")\n",
    "    if len(all_fgb_files) > 10:\n",
    "        print(f\"     ... and {len(all_fgb_files) - 10} more\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "else:\n",
    "    print(\"\\n No FlatGeobuf files found in scratch directory\")\n",
    "    if fgb_results.get('skipped', 0) > 0:\n",
    "        print(f\"All {fgb_results['skipped']} Overture files already converted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60968d93",
   "metadata": {},
   "source": [
    "## 4. Process FlatGeobuf to PMTiles\n",
    "\n",
    "Use the `runCreateTiles.py` module to convert FlatGeobuf files to PMTiles using custom tippecanoe queries from tippecanoe.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a575ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Process all geospatial files to PMTiles\n",
    "print(\"=== STEP 4: PROCESSING TO PMTILES ===\")\n",
    "\n",
    "# Process all downloaded and converted files to PMTiles using CONFIG settings\n",
    "# Now supports: GeoJSON, GeoJSONSeq, and GeoParquet formats\n",
    "tiling_results = process_to_tiles(\n",
    "    extent=CONFIG[\"extent\"][\"coordinates\"],\n",
    "    input_dirs=[str(d) for d in CONFIG[\"tiling\"][\"input_dirs\"]],  # Convert Path objects to strings\n",
    "    filter_pattern=CONFIG[\"tiling\"][\"filter_pattern\"],  # Pass filter pattern from CONFIG\n",
    "    output_dir=str(CONFIG[\"tiling\"][\"output_dir\"]),  # Use explicit output directory from CONFIG\n",
    "    parallel=CONFIG[\"tiling\"][\"parallel\"],\n",
    "    verbose=CONFIG[\"tiling\"][\"verbose\"]\n",
    ")\n",
    "\n",
    "# print(f\"Tiling completed: {tiling_results['success']}\")\n",
    "# print(f\"Files processed: {len(tiling_results['processed_files'])}/{tiling_results['total_files']}\")\n",
    "\n",
    "if tiling_results[\"errors\"]:\n",
    "    print(f\"Errors encountered: {len(tiling_results['errors'])}\")\n",
    "    for error in tiling_results[\"errors\"]:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "# Display generated PMTiles files\n",
    "if tiling_results[\"processed_files\"]:\n",
    "    print(f\"\\nâœ“ Successfully generated {len(tiling_results['processed_files'])} PMTiles:\")\n",
    "    \n",
    "    pmtiles_files = list(CONFIG[\"paths\"][\"tile_dir\"].glob(\"*.pmtiles\"))\n",
    "    \n",
    "    total_size_mb = 0\n",
    "    for pmtile in sorted(pmtiles_files):\n",
    "        size_mb = pmtile.stat().st_size / 1024 / 1024\n",
    "        total_size_mb += size_mb\n",
    "        print(f\"  {pmtile.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    print(f\"\\nTotal PMTiles size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"Files location: {CONFIG['paths']['tile_dir']}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nNo PMTiles files were generated. Check the errors above.\")\n",
    "    print(f\"Make sure you have geospatial files (GeoJSON/GeoJSONSeq/GeoParquet) in: {[str(d) for d in CONFIG['tiling']['input_dirs']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f46e1",
   "metadata": {},
   "source": [
    "## 5. Create TileJSON Metadata for map viewer\n",
    "\n",
    "- **Set bounds and zoom levels**\n",
    "- **PMTiles URL references**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57093621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 5: CREATING TILEJSON METADATA ===\n",
      "Found 6 PMTiles files, creating TileJSON...\n",
      "TileJSON created: C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\data\\3-pmtiles\\tilejson.json\n",
      "Found 6 PMTiles files\n",
      "âœ“ TileJSON created successfully\n",
      "  Bounds: [12.19, -13.46, 31.31, 5.39]\n",
      "  Zoom range: 7 - 16\n",
      "  Vector layers: 6\n",
      "  Output file: C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\data\\3-pmtiles\\tilejson.json\n",
      "\n",
      "Complete output summary:\n",
      "  addresses.pmtiles (0.0 MB)\n",
      "  base.pmtiles (3853.1 MB)\n",
      "  buildings.pmtiles (3651.7 MB)\n",
      "  divisions.pmtiles (356.9 MB)\n",
      "  places.pmtiles (28.0 MB)\n",
      "  transportation.pmtiles (987.8 MB)\n",
      "  tilejson.json\n",
      "\n",
      "Total PMTiles size: 8877.5 MB\n",
      "All files location: C:\\Users\\mjh2241\\Documents\\GitHub\\mapTiles\\data\\3-pmtiles\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Create TileJSON metadata for MapLibre integration\n",
    "print(\"=== STEP 5: CREATING TILEJSON METADATA ===\")\n",
    "\n",
    "# Check if PMTiles files exist in the configured tile directory\n",
    "pmtiles_files = list(CONFIG[\"paths\"][\"tile_dir\"].glob(\"*.pmtiles\"))\n",
    "\n",
    "if pmtiles_files:\n",
    "    print(f\"Found {len(pmtiles_files)} PMTiles files, creating TileJSON...\")\n",
    "    \n",
    "    try:\n",
    "        tilejson = create_tilejson(\n",
    "            tile_dir=str(CONFIG[\"paths\"][\"tile_dir\"]),  # Explicitly pass tile directory\n",
    "            extent=CONFIG[\"extent\"][\"coordinates\"],  # Pass extent from CONFIG\n",
    "            output_file=str(CONFIG[\"paths\"][\"tile_dir\"] / \"tilejson.json\")  # Explicitly pass output file path\n",
    "        )\n",
    "        \n",
    "        print(\"âœ“ TileJSON created successfully\")\n",
    "        print(f\"  Bounds: {tilejson['bounds']}\")\n",
    "        print(f\"  Zoom range: {tilejson['minzoom']} - {tilejson['maxzoom']}\")\n",
    "        print(f\"  Vector layers: {len(tilejson['vector_layers'])}\")\n",
    "        print(f\"  Output file: {CONFIG['paths']['tile_dir'] / 'tilejson.json'}\")\n",
    "        \n",
    "        # Show a summary of all output files\n",
    "        print(f\"\\nComplete output summary:\")\n",
    "        total_size_mb = 0\n",
    "        for pmtile in sorted(pmtiles_files):\n",
    "            size_mb = pmtile.stat().st_size / 1024 / 1024\n",
    "            total_size_mb += size_mb\n",
    "            print(f\"  {pmtile.name} ({size_mb:.1f} MB)\")\n",
    "        \n",
    "        print(f\"  tilejson.json\")\n",
    "        print(f\"\\nTotal PMTiles size: {total_size_mb:.1f} MB\")\n",
    "        print(f\"All files location: {CONFIG['paths']['tile_dir']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— TileJSON creation failed: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"No PMTiles files found in output directory.\")\n",
    "    print(f\"Expected location: {CONFIG['paths']['tile_dir']}\")\n",
    "    print(\"Run Step 4 first to generate PMTiles files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7b57cd",
   "metadata": {},
   "source": [
    "## Using Cartography Properties in Map Styles\n",
    "\n",
    "The cartography and level properties extracted from Overture Maps can be used in your MapLibre style for dynamic rendering. Here are some examples:\n",
    "\n",
    "### 1. Zoom-Dependent Filtering\n",
    "Use `min_zoom` and `max_zoom` to show features only at appropriate zoom levels:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"land-cover-optimized\",\n",
    "  \"type\": \"fill\",\n",
    "  \"source\": \"land-cover-tiles\",\n",
    "  \"source-layer\": \"land-cover\",\n",
    "  \"filter\": [\n",
    "    \"all\",\n",
    "    [\">=\", [\"zoom\"], [\"get\", \"min_zoom\"]],\n",
    "    [\"<=\", [\"zoom\"], [\"get\", \"max_zoom\"]]\n",
    "  ],\n",
    "  \"paint\": {\n",
    "    \"fill-color\": [\"get\", \"color\"]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### 2. Z-Ordering with sort_key\n",
    "Use `sort_key` for proper feature layering (lower values draw first):\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"infrastructure-sorted\",\n",
    "  \"type\": \"fill\",\n",
    "  \"source\": \"infrastructure-tiles\",\n",
    "  \"source-layer\": \"infrastructure\",\n",
    "  \"layout\": {\n",
    "    \"fill-sort-key\": [\"get\", \"sort_key\"]  // Higher sort_key = drawn on top\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### 3. Multi-Level Buildings\n",
    "Filter buildings by floor/level:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"ground-floor-buildings\",\n",
    "  \"type\": \"fill-extrusion\",\n",
    "  \"source\": \"buildings-tiles\",\n",
    "  \"source-layer\": \"buildings\",\n",
    "  \"filter\": [\"==\", [\"get\", \"level\"], 0],  // Only ground floor\n",
    "  \"paint\": {\n",
    "    \"fill-extrusion-height\": [\"get\", \"height\"],\n",
    "    \"fill-extrusion-base\": 0\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### 4. Combined Approach\n",
    "Combine properties for sophisticated rendering:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"land-use-advanced\",\n",
    "  \"type\": \"fill\",\n",
    "  \"source\": \"land-use-tiles\",\n",
    "  \"source-layer\": \"land-use\",\n",
    "  \"filter\": [\n",
    "    \"all\",\n",
    "    [\">=\", [\"zoom\"], [\"coalesce\", [\"get\", \"min_zoom\"], 0]],  // Fallback to 0\n",
    "    [\"<=\", [\"zoom\"], [\"coalesce\", [\"get\", \"max_zoom\"], 22]]  // Fallback to 22\n",
    "  ],\n",
    "  \"layout\": {\n",
    "    \"fill-sort-key\": [\"coalesce\", [\"get\", \"sort_key\"], 0]\n",
    "  },\n",
    "  \"paint\": {\n",
    "    \"fill-opacity\": [\n",
    "      \"interpolate\", [\"linear\"], [\"zoom\"],\n",
    "      [\"coalesce\", [\"get\", \"min_zoom\"], 8], 0,     // Fade in at min_zoom\n",
    "      [\"+\", [\"coalesce\", [\"get\", \"min_zoom\"], 8], 1], 1  // Full opacity 1 zoom level later\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Note:** Properties are automatically preserved through the conversion pipeline:\n",
    "- `tileQueries.sql` extracts properties from Overture Maps Parquet\n",
    "- `convertToFlatGeobuf.py` preserves all attributes during conversion\n",
    "- `tippecanoe.py` includes properties in PMTiles output\n",
    "- MapLibre can access properties via `[\"get\", \"property_name\"]` expressions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
