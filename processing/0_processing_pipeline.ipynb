{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64af477f",
   "metadata": {},
   "source": [
    "# Geospatial Data Processing Pipeline\n",
    "\n",
    "## Key Features\n",
    "- **Overture Maps download** via DuckDB with bounding box filtering\n",
    "- **Multi-format conversion** (Shapefile, GeoPackage, etc.) to GeoJSON\n",
    "- **Automated PMTiles generation** with tippecanoe settings per geometry type and/or theme\n",
    "\n",
    "## Processing Steps\n",
    "1. **Download** - Fetch Overture Maps data for specified extent\n",
    "2. **Convert** - Transform custom spatial data to GeoJSON format\n",
    "3. **Tile** - Generate PMTiles using tippecanoe with custom settings\n",
    "\n",
    "## Prerequisites\n",
    "- Python with required packages (duckdb, tqdm, pathlib)\n",
    "- Tippecanoe installed and available in PATH\n",
    "- GDAL/OGR for geospatial format conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89e8a8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported all processing modules\n"
     ]
    }
   ],
   "source": [
    "# Import the three modular processing scripts\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Add the processing directory to Python path\n",
    "processing_dir = Path(\"./processing\")\n",
    "if str(processing_dir) not in sys.path:\n",
    "    sys.path.append(str(processing_dir))\n",
    "\n",
    "# Import modular processing scripts\n",
    "try:\n",
    "    from downloadOverture import download_overture_data\n",
    "    from convertCustomData import convert_file\n",
    "    from runCreateTiles import process_to_tiles, create_tilejson\n",
    "    print(\"Successfully imported all processing modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(\"Make sure the processing scripts are in the ./processing directory\")\n",
    "\n",
    "# Import additional libraries for visualization and analysis\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008eff0",
   "metadata": {},
   "source": [
    "## 1. Project Configuration and Paths\n",
    "\n",
    "Configure the project directories and processing parameters for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09545d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT CONFIGURATION INITIALIZED\n",
      "==================================================\n",
      "Project root: /Users/matthewheaton/GitHub/basemap\n",
      "Processing directory: /Users/matthewheaton/GitHub/basemap/processing\n",
      "Data directory: /Users/matthewheaton/GitHub/basemap/processing/data\n",
      "Output directory: /Users/matthewheaton/GitHub/basemap/processing/data/processed\n",
      "Overture data directory: /Users/matthewheaton/GitHub/basemap/processing/data/raw/overture\n",
      "Custom data directory: /Users/matthewheaton/GitHub/basemap/processing/data/raw/grid3\n",
      "Tile output directory: /Users/matthewheaton/GitHub/basemap/processing/data/tiles\n",
      "Public tiles directory: /Users/matthewheaton/GitHub/basemap/public/tiles\n",
      "\n",
      "Processing extent: (22.0, -6.0, 24.0, -4.0)\n",
      "Buffer degrees: 0.2\n",
      "Area: 4.00 degree²\n",
      "\n",
      "All directories created and configuration loaded\n",
      "All modular functions will use CONFIG parameters instead of hardcoded defaults\n"
     ]
    }
   ],
   "source": [
    "# Configuration - All paths and parameters centralized\n",
    "from pathlib import Path\n",
    "\n",
    "# Define all project paths\n",
    "PROJECT_ROOT = Path(__file__).resolve().parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "PROCESSING_DIR = PROJECT_ROOT / \"processing\"\n",
    "DATA_DIR = PROCESSING_DIR / \"data\"\n",
    "OVERTURE_DATA_DIR = DATA_DIR / \"raw\" / \"overture\"\n",
    "CUSTOM_DATA_DIR = DATA_DIR / \"raw\" / \"grid3\"\n",
    "OUTPUT_DIR = DATA_DIR / \"processed\"\n",
    "TILE_DIR = DATA_DIR / \"tiles\"\n",
    "PUBLIC_TILES_DIR = PROJECT_ROOT / \"public\" / \"tiles\"\n",
    "\n",
    "CONFIG = {\n",
    "    \"paths\": {\n",
    "        \"project_root\": PROJECT_ROOT,\n",
    "        \"processing_dir\": PROCESSING_DIR,\n",
    "        \"data_dir\": DATA_DIR,\n",
    "        \"overture_data_dir\": OVERTURE_DATA_DIR,\n",
    "        \"custom_data_dir\": CUSTOM_DATA_DIR,\n",
    "        \"tile_dir\": TILE_DIR,\n",
    "        \"output_dir\" : OUTPUT_DIR,\n",
    "        \"public_tiles_dir\": PUBLIC_TILES_DIR,\n",
    "        \"template_path\": PROCESSING_DIR / \"tileQueries.template\"\n",
    "    },\n",
    "    \"extent\": {\n",
    "        \"coordinates\": (22.0, -6.0, 24.0, -4.0),  # kasai-oriental\n",
    "        \"buffer_degrees\": 0.2\n",
    "    },\n",
    "    \"download\": {\n",
    "        \"verbose\": True,\n",
    "        \"output_formats\": [\"*.geojson\", \"*.geojsonseq\"]\n",
    "    },\n",
    "    \"conversion\": {\n",
    "        \"input_patterns\": [\"*.shp\", \"*.gpkg\", \"*.gdb\", \"*.sqlite\", \"*.db\", \"*.geojson\", \"*.json\"],\n",
    "        \"output_suffix\": \".geojsonseq\",\n",
    "        \"reproject_crs\": \"EPSG:4326\",\n",
    "        \"overwrite\": True,\n",
    "        \"verbose\": True\n",
    "    },\n",
    "    \"tiling\": {\n",
    "        \"input_dirs\": [CUSTOM_DATA_DIR, OVERTURE_DATA_DIR],  # Search in both data directories\n",
    "        \"output_dir\": TILE_DIR,  # Explicit output directory for PMTiles\n",
    "        \"parallel\": True,\n",
    "        \"overwrite\": True,\n",
    "        \"verbose\": True,\n",
    "        \"create_tilejson\": True,\n",
    "        \"filter_pattern\": None  # Optional: filter files by pattern\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create necessary directories\n",
    "for path_key, path_value in CONFIG[\"paths\"].items():\n",
    "    if path_key.endswith(\"_dir\") and path_value:\n",
    "        path_value.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Display configuration summary\n",
    "print(\"PROJECT CONFIGURATION INITIALIZED\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Project root: {CONFIG['paths']['project_root']}\")\n",
    "print(f\"Processing directory: {CONFIG['paths']['processing_dir']}\")\n",
    "print(f\"Data directory: {CONFIG['paths']['data_dir']}\")\n",
    "print(f\"Output directory: {CONFIG['paths']['output_dir']}\")\n",
    "print(f\"Overture data directory: {CONFIG['paths']['overture_data_dir']}\")\n",
    "print(f\"Custom data directory: {CONFIG['paths']['custom_data_dir']}\")\n",
    "print(f\"Tile output directory: {CONFIG['paths']['tile_dir']}\")\n",
    "print(f\"Public tiles directory: {CONFIG['paths']['public_tiles_dir']}\")\n",
    "print()\n",
    "print(f\"Processing extent: {CONFIG['extent']['coordinates']}\")\n",
    "print(f\"Buffer degrees: {CONFIG['extent']['buffer_degrees']}\")\n",
    "print(f\"Area: {(CONFIG['extent']['coordinates'][2] - CONFIG['extent']['coordinates'][0]) * (CONFIG['extent']['coordinates'][3] - CONFIG['extent']['coordinates'][1]):.2f} degree²\")\n",
    "print()\n",
    "print(\"All directories created and configuration loaded\")\n",
    "print(\"All modular functions will use CONFIG parameters instead of hardcoded defaults\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea97440",
   "metadata": {},
   "source": [
    "## 2. Download Overture Data with DuckDB\n",
    "\n",
    "Use the `downloadOverture.py` module to fetch geospatial data from Overture Maps. This module uses DuckDB to efficiently query and download data for specific geographic extents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b170545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 1: DOWNLOADING OVERTURE DATA ===\n",
      "=== DOWNLOADING SOURCE DATA ===\n",
      "Raw extent: (22.0, -6.0, 24.0, -4.0)\n",
      "Snapped extent: (21.09375, -7.0136679275666305, 25.3125, -2.8113711933311296)\n",
      "Map extent: 21.09375, -7.0136679275666305 to 25.3125, -2.8113711933311296\n",
      "Download extent (buffered): 20.89375, -7.213667927566631 to 25.5125, -2.6113711933311294\n",
      "Buffer: 0.2 degrees (~22.2km)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:   0%|          | 0/10 [00:00<?, ?section/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 1: base/land\n",
      "  -> Querying: s3://overturemaps-us-west-2/release/2025-06-25.0/theme=base/type=land/*\n",
      "  -> Output: land.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  10%|█         | 1/10 [00:43<06:28, 43.15s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 2: base/land_use\n",
      "  -> Querying: s3://overturemaps-us-west-2/release/2025-06-25.0/theme=base/type=land_use/*\n",
      "  -> Output: land_use.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  20%|██        | 2/10 [01:16<05:00, 37.56s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 3: base/land_use\n",
      "  -> Querying: s3://overturemaps-us-west-2/release/2025-06-25.0/theme=base/type=land_use/*\n",
      "  -> Output: land_residential.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  30%|███       | 3/10 [01:21<02:36, 22.35s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 4: base/water\n",
      "  -> Querying: s3://overturemaps-us-west-2/release/2025-06-25.0/theme=base/type=water/*\n",
      "  -> Output: water.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  40%|████      | 4/10 [02:19<03:40, 36.69s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 5: transportation/segment\n",
      "  -> Querying: s3://overturemaps-us-west-2/release/2025-06-25.0/theme=transportation/type=segment/*\n",
      "  -> Output: roads.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  50%|█████     | 5/10 [04:24<05:42, 68.60s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 6: buildings/building\n",
      "  -> Querying: az://overturemapswestus2.blob.core.windows.net/release/2025-06-25.0/theme=buildings/type=building/*\n",
      "  -> Output: buildings.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  60%|██████    | 6/10 [09:47<10:20, 155.07s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 7: admins/locality\n",
      "  -> Querying: az://overturemapswestus2.blob.core.windows.net/release/2024-04-16-beta.0/theme=admins/type=locality/*\n",
      "  -> Output: placenames.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  70%|███████   | 7/10 [09:53<05:18, 106.22s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 8: unknown\n",
      "  -> Querying: s3://overturemaps-us-west-2/release/2025-06-25.0/theme=places/*/*\n",
      "  -> Output: places.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  80%|████████  | 8/10 [10:04<02:31, 75.97s/section] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 9: base/land_cover\n",
      "  -> Querying: az://overturemapswestus2.blob.core.windows.net/release/2025-06-25.0/theme=base/type=land_cover/*\n",
      "  -> Output: land_cover.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  90%|█████████ | 9/10 [12:48<01:43, 103.57s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 10: base/infrastructure\n",
      "  -> Querying: az://overturemapswestus2.blob.core.windows.net/release/2025-06-25.0/theme=base/type=infrastructure/*\n",
      "  -> Output: infrastructure.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress: 100%|██████████| 10/10 [13:02<00:00, 78.23s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SOURCE DATA DOWNLOAD COMPLETE ===\n",
      "\n",
      "Download completed: True\n",
      "Sections processed: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download Overture Maps data\n",
    "print(\"=== STEP 1: DOWNLOADING OVERTURE DATA ===\")\n",
    "download_results = download_overture_data(\n",
    "    extent=CONFIG[\"extent\"][\"coordinates\"],\n",
    "    buffer_degrees=CONFIG[\"extent\"][\"buffer_degrees\"],\n",
    "    template_path=str(CONFIG[\"paths\"][\"template_path\"]),\n",
    "    verbose=CONFIG[\"download\"][\"verbose\"],\n",
    "    project_root=str(CONFIG[\"paths\"][\"project_root\"]),\n",
    "    overture_data_dir=str(CONFIG[\"paths\"][\"overture_data_dir\"])\n",
    ")\n",
    "\n",
    "print(f\"Download completed: {download_results['success']}\")\n",
    "print(f\"Sections processed: {download_results['processed_sections']}\")\n",
    "if download_results[\"errors\"]:\n",
    "    print(f\"Errors encountered: {len(download_results['errors'])}\")\n",
    "    for error in download_results[\"errors\"]:\n",
    "        print(f\"  - {error}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what files were created during download\n",
    "print(\"=== CHECKING DOWNLOADED FILES ===\")\n",
    "\n",
    "overture_files = []\n",
    "search_dirs = [CONFIG[\"paths\"][\"data_dir\"], CONFIG[\"paths\"][\"overture_data_dir\"]]\n",
    "\n",
    "for data_dir in search_dirs:\n",
    "    if data_dir.exists():\n",
    "        for pattern in CONFIG[\"download\"][\"output_formats\"]:\n",
    "            files = list(data_dir.glob(pattern))\n",
    "            overture_files.extend(files)\n",
    "\n",
    "print(f\"Found {len(overture_files)} downloaded files:\")\n",
    "for file in sorted(overture_files):\n",
    "    file_size = file.stat().st_size / 1024 / 1024  # Size in MB\n",
    "    print(f\"  {file.name} ({file_size:.1f} MB)\")\n",
    "\n",
    "# Display file statistics\n",
    "if overture_files:\n",
    "    total_size_mb = sum(f.stat().st_size for f in overture_files) / 1024 / 1024\n",
    "    print(f\"\\nTotal size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"Search directories: {[str(d) for d in search_dirs]}\")\n",
    "else:\n",
    "    print(\"No files found. Check download results above.\")\n",
    "    print(f\"Searched in: {[str(d) for d in search_dirs]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bacbe99",
   "metadata": {},
   "source": [
    "## 3. Convert Custom Spatial Data for Tippecanoe\n",
    "\n",
    "Use the `convertCustomData.py` module to convert various geospatial formats to newline-delimited GeoJSON files suitable for Tippecanoe \n",
    "\n",
    "### Supported Input Formats\n",
    "- Shapefile (.shp)\n",
    "- GeoPackage (.gpkg)\n",
    "- FileGDB (.gdb)\n",
    "- SQLite/SpatiaLite (.sqlite, .db)\n",
    "- PostGIS (connection string)\n",
    "- CSV with geometry columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f4d5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 3: CONVERTING CUSTOM SPATIAL DATA ===\n",
      "Found 5 custom data files to convert:\n",
      "Search directory: /Users/matthewheaton/GitHub/basemap/processing/data/raw/grid3\n",
      "  GRID3_COD_Settlement_Extents_v3_1.gpkg\n",
      "  GRID3_COD_health_zones_v5_0.geojson\n",
      "  GRID3_COD_health_facilities_v5_0.geojson\n",
      "  GRID3_COD_health_areas_v5_0.geojson\n",
      "  GRID3_COD_settlement_names_v5_0.geojson\n",
      "Converting GRID3_COD_Settlement_Extents_v3_1.gpkg...\n",
      "Processing 572537 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:   2%|▏         | 10507/572537 [00:03<02:24, 3901.34features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 10000 features, 2980.6 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:   4%|▎         | 20405/572537 [00:06<03:09, 2910.50features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 20000 features, 3313.4 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:   5%|▌         | 30799/572537 [00:10<02:24, 3739.74features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 30000 features, 2884.4 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:   7%|▋         | 40059/572537 [00:13<02:07, 4188.34features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 40000 features, 3534.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:   9%|▉         | 50538/572537 [00:16<02:10, 3993.55features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 50000 features, 3342.5 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  11%|█         | 60499/572537 [00:19<03:56, 2168.49features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 60000 features, 3040.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  12%|█▏        | 70655/572537 [00:21<01:59, 4193.79features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 70000 features, 4067.1 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  14%|█▍        | 80621/572537 [00:24<01:55, 4247.71features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 80000 features, 3968.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  16%|█▌        | 90356/572537 [00:27<02:06, 3821.94features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 90000 features, 3806.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  18%|█▊        | 100764/572537 [00:29<01:57, 4011.80features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 100000 features, 3758.5 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  19%|█▉        | 110616/572537 [00:32<01:54, 4035.60features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 110000 features, 3976.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  21%|██        | 120415/572537 [00:34<02:06, 3563.75features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 120000 features, 3709.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  23%|██▎       | 130504/572537 [00:37<02:08, 3435.68features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 130000 features, 3685.5 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  25%|██▍       | 140570/572537 [00:40<02:18, 3115.23features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 140000 features, 3626.3 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  26%|██▋       | 150549/572537 [00:43<01:36, 4359.12features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 150000 features, 3846.9 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  28%|██▊       | 160756/572537 [00:46<02:01, 3400.99features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 160000 features, 3124.0 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  30%|██▉       | 170292/572537 [00:48<01:52, 3567.78features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 170000 features, 3609.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  32%|███▏      | 180452/572537 [00:51<01:58, 3305.65features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 180000 features, 3549.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  33%|███▎      | 190562/572537 [00:54<01:40, 3802.15features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 190000 features, 3643.4 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  35%|███▍      | 200359/572537 [00:57<01:46, 3488.10features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 200000 features, 3771.9 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  37%|███▋      | 210571/572537 [00:59<01:48, 3333.78features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 210000 features, 3640.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  39%|███▊      | 220577/572537 [01:02<01:53, 3088.24features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 220000 features, 3464.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  40%|████      | 230558/572537 [01:05<02:05, 2734.47features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 230000 features, 3386.0 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  42%|████▏     | 240693/572537 [01:08<01:25, 3892.45features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 240000 features, 3942.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  44%|████▎     | 250466/572537 [01:11<01:36, 3349.16features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 250000 features, 3652.6 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  45%|████▌     | 260425/572537 [01:13<01:24, 3672.63features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 260000 features, 4001.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  47%|████▋     | 270811/572537 [01:16<01:12, 4145.29features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 270000 features, 3424.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  49%|████▉     | 280380/572537 [01:19<01:38, 2965.25features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 280000 features, 3125.4 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  51%|█████     | 290751/572537 [01:22<01:21, 3468.64features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 290000 features, 3278.9 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  52%|█████▏    | 300268/572537 [01:25<01:08, 3990.15features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 300000 features, 3165.4 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  54%|█████▍    | 310451/572537 [01:28<01:05, 3973.87features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 310000 features, 3455.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  56%|█████▌    | 320466/572537 [01:32<01:08, 3694.44features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 320000 features, 2995.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  58%|█████▊    | 330378/572537 [01:34<01:08, 3510.53features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 330000 features, 3677.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  59%|█████▉    | 340618/572537 [01:37<01:06, 3484.77features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 340000 features, 3619.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  61%|██████    | 350334/572537 [01:40<01:08, 3236.08features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 350000 features, 3552.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  63%|██████▎   | 360517/572537 [01:43<01:04, 3288.45features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 360000 features, 3076.4 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  65%|██████▍   | 370348/572537 [01:46<00:55, 3654.02features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 370000 features, 3819.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  66%|██████▋   | 380368/572537 [01:49<00:59, 3255.34features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 380000 features, 3215.3 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  68%|██████▊   | 390628/572537 [01:51<00:48, 3719.51features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 390000 features, 4015.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  70%|███████   | 400785/572537 [01:54<00:41, 4093.28features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 400000 features, 3959.6 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  72%|███████▏  | 410361/572537 [01:57<00:48, 3335.12features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 410000 features, 3805.5 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  73%|███████▎  | 420459/572537 [01:59<00:39, 3896.59features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 420000 features, 3857.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  75%|███████▌  | 430652/572537 [02:02<00:40, 3489.33features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 430000 features, 3296.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  77%|███████▋  | 440782/572537 [02:05<00:32, 4036.67features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 440000 features, 3369.9 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  79%|███████▊  | 450600/572537 [02:08<00:35, 3446.26features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 450000 features, 3706.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  80%|████████  | 460519/572537 [02:11<00:35, 3127.56features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 460000 features, 3297.6 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  82%|████████▏ | 470742/572537 [02:14<00:29, 3506.02features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 470000 features, 2983.0 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  84%|████████▍ | 480543/572537 [02:17<00:27, 3402.92features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 480000 features, 3339.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  86%|████████▌ | 490515/572537 [02:20<00:31, 2634.99features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 490000 features, 3154.6 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  87%|████████▋ | 500359/572537 [02:23<00:20, 3515.29features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 500000 features, 3325.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  89%|████████▉ | 510605/572537 [02:26<00:15, 3995.26features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 510000 features, 3562.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  91%|█████████ | 520485/572537 [02:29<00:15, 3467.85features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 520000 features, 3427.1 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  93%|█████████▎| 530565/572537 [02:32<00:11, 3686.76features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 530000 features, 3734.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  94%|█████████▍| 540604/572537 [02:35<00:08, 3887.04features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 540000 features, 3495.1 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  96%|█████████▌| 550635/572537 [02:37<00:05, 3732.95features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 550000 features, 3709.3 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  98%|█████████▊| 560635/572537 [02:40<00:03, 3535.60features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 560000 features, 3325.3 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting: 100%|█████████▉| 570445/572537 [02:44<00:01, 1901.28features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 570000 features, 2735.6 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting: 100%|██████████| 572537/572537 [02:45<00:00, 3456.07features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete: 572537 features processed, 0 features skipped\n",
      "Output written to: /Users/matthewheaton/GitHub/basemap/processing/data/processed/GRID3_COD_Settlement_Extents_v3_1.geojsonseq\n",
      "✓ Converted: 572537 features, 0 skipped\n",
      "  Output: GRID3_COD_Settlement_Extents_v3_1.geojsonseq\n",
      "Converting GRID3_COD_health_zones_v5_0.geojson...\n",
      "Processing 329 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting: 100%|██████████| 329/329 [00:06<00:00, 52.44features/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete: 329 features processed, 0 features skipped\n",
      "Output written to: /Users/matthewheaton/GitHub/basemap/processing/data/processed/GRID3_COD_health_zones_v5_0.geojsonseq\n",
      "✓ Converted: 329 features, 0 skipped\n",
      "  Output: GRID3_COD_health_zones_v5_0.geojsonseq\n",
      "Converting GRID3_COD_health_facilities_v5_0.geojson...\n",
      "Processing 27213 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  44%|████▍     | 11922/27213 [00:01<00:01, 12020.57features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 10000 features, 11909.6 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  78%|███████▊  | 21341/27213 [00:01<00:00, 11304.19features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 20000 features, 11353.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting: 100%|██████████| 27213/27213 [00:02<00:00, 11678.06features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete: 27213 features processed, 0 features skipped\n",
      "Output written to: /Users/matthewheaton/GitHub/basemap/processing/data/processed/GRID3_COD_health_facilities_v5_0.geojsonseq\n",
      "✓ Converted: 27213 features, 0 skipped\n",
      "  Output: GRID3_COD_health_facilities_v5_0.geojsonseq\n",
      "Converting GRID3_COD_health_areas_v5_0.geojson...\n",
      "Processing 5978 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting: 100%|██████████| 5978/5978 [00:23<00:00, 249.66features/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete: 5978 features processed, 0 features skipped\n",
      "Output written to: /Users/matthewheaton/GitHub/basemap/processing/data/processed/GRID3_COD_health_areas_v5_0.geojsonseq\n",
      "✓ Converted: 5978 features, 0 skipped\n",
      "  Output: GRID3_COD_health_areas_v5_0.geojsonseq\n",
      "Converting GRID3_COD_settlement_names_v5_0.geojson...\n",
      "Processing 85680 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  15%|█▍        | 12815/85680 [00:00<00:05, 14237.14features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 10000 features, 14089.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  25%|██▌       | 21540/85680 [00:01<00:04, 14505.22features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 20000 features, 14318.0 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  37%|███▋      | 31685/85680 [00:02<00:03, 14047.40features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 30000 features, 14384.1 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  49%|████▊     | 41626/85680 [00:02<00:03, 14023.09features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 40000 features, 14055.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  60%|██████    | 51539/85680 [00:03<00:02, 13889.56features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 50000 features, 13998.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  73%|███████▎  | 62857/85680 [00:04<00:01, 14220.17features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 60000 features, 13976.3 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  85%|████████▌ | 72829/85680 [00:05<00:00, 14144.68features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 70000 features, 14111.5 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  97%|█████████▋| 82788/85680 [00:05<00:00, 14171.48features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 80000 features, 14179.9 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting: 100%|██████████| 85680/85680 [00:06<00:00, 14138.25features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete: 85680 features processed, 0 features skipped\n",
      "Output written to: /Users/matthewheaton/GitHub/basemap/processing/data/processed/GRID3_COD_settlement_names_v5_0.geojsonseq\n",
      "✓ Converted: 85680 features, 0 skipped\n",
      "  Output: GRID3_COD_settlement_names_v5_0.geojsonseq\n",
      "\n",
      "✓ Successfully converted 5 files\n",
      "  Output directory: /Users/matthewheaton/GitHub/basemap/processing/data/processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Look for custom data files to convert\n",
    "print(\"=== STEP 3: CONVERTING CUSTOM SPATIAL DATA ===\")\n",
    "\n",
    "custom_input_dir = CONFIG[\"paths\"][\"custom_data_dir\"]\n",
    "custom_files = []\n",
    "\n",
    "# Search for various spatial data formats using CONFIG patterns\n",
    "for pattern in CONFIG[\"conversion\"][\"input_patterns\"]:\n",
    "    custom_files.extend(custom_input_dir.glob(pattern))\n",
    "\n",
    "print(f\"Found {len(custom_files)} custom data files to convert:\")\n",
    "print(f\"Search directory: {custom_input_dir}\")\n",
    "for file in custom_files:\n",
    "    print(f\"  {file.name}\")\n",
    "\n",
    "# Convert custom data files (if any exist)\n",
    "converted_files = []\n",
    "\n",
    "for input_file in custom_files:\n",
    "    output_file = CONFIG[\"paths\"][\"output_dir\"] / f\"{input_file.stem}{CONFIG['conversion']['output_suffix']}\"\n",
    "    \n",
    "    print(f\"Converting {input_file.name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Convert using the modular function with CONFIG settings\n",
    "        processed, skipped, output_path = convert_file(\n",
    "            input_path=str(input_file),\n",
    "            output_path=str(output_file),\n",
    "            reproject=CONFIG[\"conversion\"][\"reproject_crs\"],\n",
    "            verbose=CONFIG[\"conversion\"][\"verbose\"]\n",
    "        )\n",
    "        \n",
    "        converted_files.append(output_file)\n",
    "        print(f\"✓ Converted: {processed} features, {skipped} skipped\")\n",
    "        print(f\"  Output: {output_file.name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error converting {input_file.name}: {e}\")\n",
    "\n",
    "if converted_files:\n",
    "    print(f\"\\n✓ Successfully converted {len(converted_files)} files\")\n",
    "    print(f\"  Output directory: {CONFIG['paths']['output_dir']}\")\n",
    "else:\n",
    "    print(f\"\\nNo custom files to convert. Add data files to: {custom_input_dir}\")\n",
    "    print(f\"Supported formats: {', '.join(CONFIG['conversion']['input_patterns'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60968d93",
   "metadata": {},
   "source": [
    "## 4. Process GeoJSON/GeoJSONSeq to PMTiles\n",
    "\n",
    "Use the `runCreateTiles.py` module to convert GeoJSON and GeoJSONSeq files to PMTiles using optimized Tippecanoe settings.\n",
    "\n",
    "### Automatic Optimization Features\n",
    "- **Geometry Detection**: Automatically detects Point, LineString, or Polygon geometries\n",
    "- **Layer-Specific Settings**: Optimized settings for water, roads, places, land use, etc.\n",
    "- **Parallel Processing**: Multi-threaded processing for large datasets\n",
    "- **Quality Optimization**: Smart simplification and feature dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11a575ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 4: PROCESSING TO PMTILES ===\n",
      "=== PROCESSING TO TILES ===\n",
      "Found 14 files to process:\n",
      "  GRID3_COD_health_zones_v5_0.geojson\n",
      "  GRID3_COD_health_facilities_v5_0.geojson\n",
      "  GRID3_COD_health_areas_v5_0.geojson\n",
      "  GRID3_COD_settlement_names_v5_0.geojson\n",
      "  placenames.geojson\n",
      "  places.geojson\n",
      "  land_use.geojsonseq\n",
      "  land_residential.geojsonseq\n",
      "  land_cover.geojsonseq\n",
      "  water.geojsonseq\n",
      "  land.geojsonseq\n",
      "  buildings.geojsonseq\n",
      "  infrastructure.geojsonseq\n",
      "  roads.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/14 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Detected geometry type: Point for GRID3_COD_health_facilities_v5_0.geojson (0.378s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   7%|▋         | 1/14 [00:02<00:34,  2.66s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GRID3_COD_health_facilities_v5_0.geojson -> /Users/matthewheaton/GitHub/basemap/processing/data/tiles/GRID3_COD_health_facilities_v5_0.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  14%|█▍        | 2/14 [00:03<00:16,  1.35s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ placenames.geojson -> /Users/matthewheaton/GitHub/basemap/processing/data/tiles/placenames.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  21%|██▏       | 3/14 [00:03<00:09,  1.11file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ places.geojson -> /Users/matthewheaton/GitHub/basemap/processing/data/tiles/places.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  29%|██▊       | 4/14 [00:03<00:06,  1.57file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ land_use.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/data/tiles/land_use.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  36%|███▌      | 5/14 [00:04<00:06,  1.31file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ land_residential.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/data/tiles/land_residential.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  43%|████▎     | 6/14 [00:05<00:05,  1.57file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GRID3_COD_settlement_names_v5_0.geojson -> /Users/matthewheaton/GitHub/basemap/processing/data/tiles/GRID3_COD_settlement_names_v5_0.pmtiles\n",
      "  Detected geometry type: Mixed for GRID3_COD_health_zones_v5_0.geojson (1.544s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  50%|█████     | 7/14 [00:07<00:08,  1.19s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ water.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/data/tiles/water.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  57%|█████▋    | 8/14 [00:13<00:17,  2.84s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ land.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/data/tiles/land.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  64%|██████▍   | 9/14 [00:15<00:13,  2.62s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GRID3_COD_health_zones_v5_0.geojson -> /Users/matthewheaton/GitHub/basemap/processing/data/tiles/GRID3_COD_health_zones_v5_0.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  71%|███████▏  | 10/14 [00:16<00:07,  1.90s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ infrastructure.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/data/tiles/infrastructure.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  79%|███████▊  | 11/14 [00:19<00:06,  2.19s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ roads.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/data/tiles/roads.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  86%|████████▌ | 12/14 [00:26<00:07,  3.93s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ land_cover.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/data/tiles/land_cover.pmtiles\n",
      "  Detected geometry type: Polygon for GRID3_COD_health_areas_v5_0.geojson (5.849s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  93%|█████████▎| 13/14 [00:39<00:06,  6.62s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GRID3_COD_health_areas_v5_0.geojson -> /Users/matthewheaton/GitHub/basemap/processing/data/tiles/GRID3_COD_health_areas_v5_0.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 14/14 [00:57<00:00,  4.14s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ buildings.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/data/tiles/buildings.pmtiles\n",
      "\n",
      "=== TILE PROCESSING COMPLETE ===\n",
      "Processed: 14/14 files\n",
      "Tiling completed: True\n",
      "Files processed: 14/14\n",
      "\n",
      "✓ Successfully generated 14 PMTiles:\n",
      "  GRID3_COD_health_areas_v5_0.pmtiles (8.7 MB)\n",
      "  GRID3_COD_health_facilities_v5_0.pmtiles (1.9 MB)\n",
      "  GRID3_COD_health_zones_v5_0.pmtiles (2.6 MB)\n",
      "  GRID3_COD_settlement_names_v5_0.pmtiles (2.1 MB)\n",
      "  buildings.pmtiles (34.8 MB)\n",
      "  infrastructure.pmtiles (0.1 MB)\n",
      "  land.pmtiles (0.3 MB)\n",
      "  land_cover.pmtiles (29.4 MB)\n",
      "  land_residential.pmtiles (1.3 MB)\n",
      "  land_use.pmtiles (0.0 MB)\n",
      "  placenames.pmtiles (0.3 MB)\n",
      "  places.pmtiles (0.2 MB)\n",
      "  roads.pmtiles (6.5 MB)\n",
      "  water.pmtiles (2.0 MB)\n",
      "\n",
      "Total PMTiles size: 90.2 MB\n",
      "Files location: /Users/matthewheaton/GitHub/basemap/processing/data/tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Process all GeoJSON/GeoJSONSeq files to PMTiles\n",
    "print(\"=== STEP 4: PROCESSING TO PMTILES ===\")\n",
    "\n",
    "# Process all downloaded and converted files to PMTiles using CONFIG settings\n",
    "tiling_results = process_to_tiles(\n",
    "    extent=CONFIG[\"extent\"][\"coordinates\"],\n",
    "    input_dirs=[str(d) for d in CONFIG[\"tiling\"][\"input_dirs\"]],  # Convert Path objects to strings\n",
    "    filter_pattern=CONFIG[\"tiling\"][\"filter_pattern\"],  # Pass filter pattern from CONFIG\n",
    "    output_dir=str(CONFIG[\"tiling\"][\"output_dir\"]),  # Use explicit output directory from CONFIG\n",
    "    parallel=CONFIG[\"tiling\"][\"parallel\"],\n",
    "    verbose=CONFIG[\"tiling\"][\"verbose\"]\n",
    ")\n",
    "\n",
    "print(f\"Tiling completed: {tiling_results['success']}\")\n",
    "print(f\"Files processed: {len(tiling_results['processed_files'])}/{tiling_results['total_files']}\")\n",
    "\n",
    "if tiling_results[\"errors\"]:\n",
    "    print(f\"Errors encountered: {len(tiling_results['errors'])}\")\n",
    "    for error in tiling_results[\"errors\"]:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "# Display generated PMTiles files\n",
    "if tiling_results[\"processed_files\"]:\n",
    "    print(f\"\\n✓ Successfully generated {len(tiling_results['processed_files'])} PMTiles:\")\n",
    "    \n",
    "    pmtiles_files = list(CONFIG[\"paths\"][\"tile_dir\"].glob(\"*.pmtiles\"))\n",
    "    \n",
    "    total_size_mb = 0\n",
    "    for pmtile in sorted(pmtiles_files):\n",
    "        size_mb = pmtile.stat().st_size / 1024 / 1024\n",
    "        total_size_mb += size_mb\n",
    "        print(f\"  {pmtile.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    print(f\"\\nTotal PMTiles size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"Files location: {CONFIG['paths']['tile_dir']}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nNo PMTiles files were generated. Check the errors above.\")\n",
    "    print(f\"Make sure you have GeoJSON/GeoJSONSeq files in: {[str(d) for d in CONFIG['tiling']['input_dirs']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f46e1",
   "metadata": {},
   "source": [
    "## 5. Create TileJSON Metadata\n",
    "\n",
    "Generate TileJSON metadata files for seamless integration with web mapping libraries like MapLibre GL JS.\n",
    "\n",
    "### TileJSON Features\n",
    "- **Bounds and zoom levels** automatically detected from PMTiles\n",
    "- **Vector layer definitions** for each data layer\n",
    "- **MapLibre GL JS compatibility** for easy web integration\n",
    "- **PMTiles URL references** for efficient tile serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57093621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 5: CREATING TILEJSON METADATA ===\n",
      "Found 14 PMTiles files, creating TileJSON...\n",
      "TileJSON created: /Users/matthewheaton/GitHub/basemap/processing/data/tiles/tilejson.json\n",
      "Found 14 PMTiles files\n",
      "✓ TileJSON created successfully\n",
      "  Bounds: [22.0, -6.0, 24.0, -4.0]\n",
      "  Zoom range: 0 - 16\n",
      "  Vector layers: 14\n",
      "  Output file: /Users/matthewheaton/GitHub/basemap/processing/data/tiles/tilejson.json\n",
      "\n",
      "Complete output summary:\n",
      "  GRID3_COD_health_areas_v5_0.pmtiles (8.7 MB)\n",
      "  GRID3_COD_health_facilities_v5_0.pmtiles (1.9 MB)\n",
      "  GRID3_COD_health_zones_v5_0.pmtiles (2.6 MB)\n",
      "  GRID3_COD_settlement_names_v5_0.pmtiles (2.1 MB)\n",
      "  buildings.pmtiles (34.8 MB)\n",
      "  infrastructure.pmtiles (0.1 MB)\n",
      "  land.pmtiles (0.3 MB)\n",
      "  land_cover.pmtiles (29.4 MB)\n",
      "  land_residential.pmtiles (1.3 MB)\n",
      "  land_use.pmtiles (0.0 MB)\n",
      "  placenames.pmtiles (0.3 MB)\n",
      "  places.pmtiles (0.2 MB)\n",
      "  roads.pmtiles (6.5 MB)\n",
      "  water.pmtiles (2.0 MB)\n",
      "  tilejson.json\n",
      "\n",
      "Total PMTiles size: 90.2 MB\n",
      "All files location: /Users/matthewheaton/GitHub/basemap/processing/data/tiles\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Create TileJSON metadata for MapLibre integration\n",
    "print(\"=== STEP 5: CREATING TILEJSON METADATA ===\")\n",
    "\n",
    "# Check if PMTiles files exist in the configured tile directory\n",
    "pmtiles_files = list(CONFIG[\"paths\"][\"tile_dir\"].glob(\"*.pmtiles\"))\n",
    "\n",
    "if pmtiles_files:\n",
    "    print(f\"Found {len(pmtiles_files)} PMTiles files, creating TileJSON...\")\n",
    "    \n",
    "    try:\n",
    "        tilejson = create_tilejson(\n",
    "            tile_dir=str(CONFIG[\"paths\"][\"tile_dir\"]),  # Explicitly pass tile directory\n",
    "            extent=CONFIG[\"extent\"][\"coordinates\"],  # Pass extent from CONFIG\n",
    "            output_file=str(CONFIG[\"paths\"][\"tile_dir\"] / \"tilejson.json\")  # Explicitly pass output file path\n",
    "        )\n",
    "        \n",
    "        print(\"✓ TileJSON created successfully\")\n",
    "        print(f\"  Bounds: {tilejson['bounds']}\")\n",
    "        print(f\"  Zoom range: {tilejson['minzoom']} - {tilejson['maxzoom']}\")\n",
    "        print(f\"  Vector layers: {len(tilejson['vector_layers'])}\")\n",
    "        print(f\"  Output file: {CONFIG['paths']['tile_dir'] / 'tilejson.json'}\")\n",
    "        \n",
    "        # Show a summary of all output files\n",
    "        print(f\"\\nComplete output summary:\")\n",
    "        total_size_mb = 0\n",
    "        for pmtile in sorted(pmtiles_files):\n",
    "            size_mb = pmtile.stat().st_size / 1024 / 1024\n",
    "            total_size_mb += size_mb\n",
    "            print(f\"  {pmtile.name} ({size_mb:.1f} MB)\")\n",
    "        \n",
    "        print(f\"  tilejson.json\")\n",
    "        print(f\"\\nTotal PMTiles size: {total_size_mb:.1f} MB\")\n",
    "        print(f\"All files location: {CONFIG['paths']['tile_dir']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ TileJSON creation failed: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"No PMTiles files found in output directory.\")\n",
    "    print(f\"Expected location: {CONFIG['paths']['tile_dir']}\")\n",
    "    print(\"Run Step 4 first to generate PMTiles files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755057e5",
   "metadata": {},
   "source": [
    "## 6. Validate and Test Individual Steps\n",
    "\n",
    "Test each processing step individually and validate the generated outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed67893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual Step Testing and Validation\n",
    "\n",
    "print(\"INDIVIDUAL STEP TESTING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n1. Test downloadOverture.py standalone:\")\n",
    "print(\"python processing/downloadOverture.py --extent='23.4,-6.2,23.8,-5.8' --buffer=0.1\")\n",
    "\n",
    "print(\"\\n2. Test convertCustomData.py standalone:\")\n",
    "print(\"python processing/convertCustomData.py input.shp output.geojsonseq --reproject=EPSG:4326\")\n",
    "\n",
    "print(\"\\n3. Test runCreateTiles.py standalone:\")\n",
    "print(\"python processing/runCreateTiles.py --extent='23.4,-6.2,23.8,-5.8' --create-tilejson\")\n",
    "\n",
    "print(\"\\n4. Test individual steps in this notebook:\")\n",
    "print(\"   - Step 1: Download section (cell 6)\")\n",
    "print(\"   - Step 2: Check downloaded files (cell 7)\")\n",
    "print(\"   - Step 3: Convert custom data (cell 9)\")\n",
    "print(\"   - Step 4: Process to PMTiles (cell 11)\")\n",
    "print(\"   - Step 5: Create TileJSON (cell 13)\")\n",
    "\n",
    "print(\"\\n5. Validate outputs using CONFIG paths:\")\n",
    "print(f\"   - Check {CONFIG['paths']['data_dir']} for GeoJSON files\")\n",
    "print(f\"   - Check {CONFIG['paths']['tile_dir']} for PMTiles files\")\n",
    "print(f\"   - Verify TileJSON metadata file\")\n",
    "\n",
    "# Configuration validation using centralized CONFIG\n",
    "print(\"\\nCURRENT CONFIGURATION VALIDATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Extent: {CONFIG['extent']['coordinates']}\")\n",
    "print(f\"Buffer: {CONFIG['extent']['buffer_degrees']} degrees\")\n",
    "print(f\"Tile output directory: {CONFIG['paths']['tile_dir']}\")\n",
    "print(f\"Custom data directory: {CONFIG['paths']['custom_data_dir']}\")\n",
    "print(f\"Input directories for tiling: {[str(d) for d in CONFIG['tiling']['input_dirs']]}\")\n",
    "\n",
    "# Area calculation using CONFIG\n",
    "extent = CONFIG['extent']['coordinates']\n",
    "area = (extent[2] - extent[0]) * (extent[3] - extent[1])\n",
    "print(f\"Processing area: {area:.2f} degree² ({area * 111**2:.0f} km²)\")\n",
    "\n",
    "# Check directory status\n",
    "print(f\"\\nDIRECTORY STATUS\")\n",
    "print(\"=\" * 30)\n",
    "for path_name, path_obj in CONFIG['paths'].items():\n",
    "    if path_name.endswith('_dir'):\n",
    "        status = \"exists\" if path_obj.exists() else \"missing\"\n",
    "        file_count = len(list(path_obj.glob(\"*\"))) if path_obj.exists() else 0\n",
    "        print(f\"{path_name}: {status} ({file_count} files)\")\n",
    "\n",
    "print(\"\\nPERFORMANCE OPTIMIZATION TIPS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n1. For large areas (current: {area:.2f} degree²):\")\n",
    "print(f\"   - Current buffer: {CONFIG['extent']['buffer_degrees']} degrees\")\n",
    "print(f\"   - Parallel processing: {CONFIG['tiling']['parallel']}\")\n",
    "print(\"   - Consider smaller chunks if memory issues occur\")\n",
    "\n",
    "print(\"\\n2. File management:\")\n",
    "print(f\"   - Monitor {CONFIG['paths']['data_dir']} size during processing\")\n",
    "print(\"   - Clean intermediate files between steps if needed\")\n",
    "print(\"   - Use filter patterns to process specific layers only\")\n",
    "\n",
    "print(\"\\n3. Output optimization:\")\n",
    "print(f\"   - PMTiles output: {CONFIG['paths']['tile_dir']}\")\n",
    "print(f\"   - Public tiles: {CONFIG['paths']['public_tiles_dir']}\")\n",
    "print(\"   - Copy final tiles to public directory for web serving\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ee77b",
   "metadata": {},
   "source": [
    "# Modular Processing Summary\n",
    "\n",
    "This notebook provides a complete, step-by-step approach for geospatial data processing with the following capabilities:\n",
    "\n",
    "## Core Steps\n",
    "1. **Download Overture Maps data** with spatial filtering using DuckDB\n",
    "2. **Check and validate** downloaded files \n",
    "3. **Convert custom spatial data** to GeoJSON format\n",
    "4. **Generate PMTiles** using optimized tippecanoe settings\n",
    "5. **Create TileJSON metadata** for web mapping integration\n",
    "6. **Validate and test** individual processing steps\n",
    "\n",
    "## Key Features\n",
    "- **Modular design** - Each step can be run independently\n",
    "- **Flexible configuration** - Easy to customize for different areas and data types\n",
    "- **Interactive development** - Run steps individually for debugging\n",
    "- **Performance optimized** - Appropriate settings for different geometry types\n",
    "- **Production ready** - Robust error handling and validation\n",
    "\n",
    "## Output Files\n",
    "Each step generates specific outputs that can be directly used:\n",
    "- **GeoJSON/GeoJSONSeq files** for further processing or analysis\n",
    "- **PMTiles files** for efficient web mapping\n",
    "- **TileJSON metadata** for MapLibre GL JS integration\n",
    "\n",
    "## Usage Patterns\n",
    "- **Development**: Run steps individually for testing and debugging\n",
    "- **Production**: Execute all steps in sequence for automated processing\n",
    "- **Customization**: Modify CONFIG settings and re-run specific steps\n",
    "- **Integration**: Use generated files with web mapping applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
